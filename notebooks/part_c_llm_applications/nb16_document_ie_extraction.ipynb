{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a26e5",
   "metadata": {},
   "outputs": [],
   "source": [
    " Document Information Extraction and Structuring\n",
    "# 文件結構化抽取與驗證 - 使用 LLM 進行智能文件解析\n",
    "\n",
    "## 1. Environment Setup & Dependencies\n",
    "# 環境初始化與依賴管理\n",
    "\n",
    "# === Shared Cache Bootstrap ===\n",
    "import os, pathlib, torch\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"/mnt/ai/cache\")\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"[Cache]\", AI_CACHE_ROOT, \"| GPU:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"[GPU] {torch.cuda.get_device_name(0)} | VRAM: {torch.cuda.get_device_properties(0).total_memory // 1e9:.1f}GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc6932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# 安裝文件處理與驗證相關套件\n",
    "!pip install -q transformers accelerate bitsandbytes\n",
    "!pip install -q PyPDF2 python-docx beautifulsoup4 lxml\n",
    "!pip install -q pydantic rich spacy nltk\n",
    "!pip install -q pandas openpyxl tabulate\n",
    "\n",
    "## 2. Document Parser - Multi-format Support\n",
    "# 多格式文件解析器 - 統一文件讀取介面\n",
    "\n",
    "import PyPDF2\n",
    "import docx\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Union, Optional\n",
    "from dataclasses import dataclass\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ab568",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DocumentContent:\n",
    "    \"\"\"Structured document content with metadata\"\"\"\n",
    "    text: str\n",
    "    title: Optional[str] = None\n",
    "    pages: Optional[int] = None\n",
    "    tables: List[pd.DataFrame] = None\n",
    "    metadata: Dict = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.tables is None:\n",
    "            self.tables = []\n",
    "        if self.metadata is None:\n",
    "            self.metadata = {}\n",
    "\n",
    "class DocumentParser:\n",
    "    \"\"\"Universal document parser supporting PDF, DOCX, HTML, TXT, MD\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.supported_formats = {'.pdf', '.docx', '.html', '.htm', '.txt', '.md'}\n",
    "\n",
    "    def parse(self, file_path: Union[str, Path]) -> DocumentContent:\n",
    "        \"\"\"Parse document and return structured content\"\"\"\n",
    "        file_path = Path(file_path)\n",
    "\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "        extension = file_path.suffix.lower()\n",
    "        if extension not in self.supported_formats:\n",
    "            raise ValueError(f\"Unsupported format: {extension}\")\n",
    "\n",
    "        if extension == '.pdf':\n",
    "            return self._parse_pdf(file_path)\n",
    "        elif extension == '.docx':\n",
    "            return self._parse_docx(file_path)\n",
    "        elif extension in ['.html', '.htm']:\n",
    "            return self._parse_html(file_path)\n",
    "        elif extension in ['.txt', '.md']:\n",
    "            return self._parse_text(file_path)\n",
    "\n",
    "    def _parse_pdf(self, file_path: Path) -> DocumentContent:\n",
    "        \"\"\"Extract text and metadata from PDF\"\"\"\n",
    "        with open(file_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "            # Extract text from all pages\n",
    "            text_parts = []\n",
    "            for page in reader.pages:\n",
    "                text_parts.append(page.extract_text())\n",
    "\n",
    "            text = '\\n\\n'.join(text_parts)\n",
    "\n",
    "            # Extract metadata\n",
    "            metadata = {\n",
    "                'file_path': str(file_path),\n",
    "                'file_size': file_path.stat().st_size,\n",
    "                'format': 'pdf'\n",
    "            }\n",
    "\n",
    "            if reader.metadata:\n",
    "                metadata.update({\n",
    "                    'title': reader.metadata.get('/Title', ''),\n",
    "                    'author': reader.metadata.get('/Author', ''),\n",
    "                    'subject': reader.metadata.get('/Subject', ''),\n",
    "                    'creator': reader.metadata.get('/Creator', '')\n",
    "                })\n",
    "\n",
    "            return DocumentContent(\n",
    "                text=text,\n",
    "                title=metadata.get('title'),\n",
    "                pages=len(reader.pages),\n",
    "                metadata=metadata\n",
    "            )\n",
    "\n",
    "    def _parse_docx(self, file_path: Path) -> DocumentContent:\n",
    "        \"\"\"Extract text and tables from DOCX\"\"\"\n",
    "        doc = docx.Document(file_path)\n",
    "\n",
    "        # Extract paragraphs\n",
    "        text_parts = [paragraph.text for paragraph in doc.paragraphs if paragraph.text.strip()]\n",
    "        text = '\\n\\n'.join(text_parts)\n",
    "\n",
    "        # Extract tables\n",
    "        tables = []\n",
    "        for table in doc.tables:\n",
    "            data = []\n",
    "            for row in table.rows:\n",
    "                row_data = [cell.text.strip() for cell in row.cells]\n",
    "                data.append(row_data)\n",
    "\n",
    "            if data:\n",
    "                df = pd.DataFrame(data[1:], columns=data[0] if data else None)\n",
    "                tables.append(df)\n",
    "\n",
    "        metadata = {\n",
    "            'file_path': str(file_path),\n",
    "            'file_size': file_path.stat().st_size,\n",
    "            'format': 'docx',\n",
    "            'paragraphs': len(doc.paragraphs),\n",
    "            'tables': len(tables)\n",
    "        }\n",
    "\n",
    "        return DocumentContent(\n",
    "            text=text,\n",
    "            tables=tables,\n",
    "            metadata=metadata\n",
    "        )\n",
    "\n",
    "    def _parse_html(self, file_path: Path) -> DocumentContent:\n",
    "        \"\"\"Extract text from HTML\"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file.read(), 'html.parser')\n",
    "\n",
    "        # Remove script and style elements\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.decompose()\n",
    "\n",
    "        # Extract text\n",
    "        text = soup.get_text()\n",
    "        text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)  # Clean up whitespace\n",
    "\n",
    "        # Extract title\n",
    "        title = soup.title.string if soup.title else None\n",
    "\n",
    "        metadata = {\n",
    "            'file_path': str(file_path),\n",
    "            'file_size': file_path.stat().st_size,\n",
    "            'format': 'html',\n",
    "            'title': title\n",
    "        }\n",
    "\n",
    "        return DocumentContent(\n",
    "            text=text,\n",
    "            title=title,\n",
    "            metadata=metadata\n",
    "        )\n",
    "\n",
    "    def _parse_text(self, file_path: Path) -> DocumentContent:\n",
    "        \"\"\"Extract text from plain text or markdown\"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # Try to extract title from first line if it looks like a title\n",
    "        lines = text.split('\\n')\n",
    "        title = None\n",
    "        if lines and (lines[0].startswith('#') or len(lines[0]) < 100):\n",
    "            title = lines[0].lstrip('#').strip()\n",
    "\n",
    "        metadata = {\n",
    "            'file_path': str(file_path),\n",
    "            'file_size': file_path.stat().st_size,\n",
    "            'format': file_path.suffix[1:],  # Remove dot\n",
    "            'lines': len(lines)\n",
    "        }\n",
    "\n",
    "        return DocumentContent(\n",
    "            text=text,\n",
    "            title=title,\n",
    "            metadata=metadata\n",
    "        )\n",
    "\n",
    "# Test document parser with sample content\n",
    "# 測試文件解析器\n",
    "sample_text = \"\"\"\n",
    "# Company Annual Report 2024\n",
    "\n",
    "## Executive Summary\n",
    "Our company achieved record growth in 2024, with revenue increasing by 25% to $150M.\n",
    "Key highlights include:\n",
    "- New product launches in Q2 and Q4\n",
    "- Expansion into Asian markets\n",
    "- Strategic partnership with TechCorp\n",
    "\n",
    "## Financial Performance\n",
    "| Metric | 2023 | 2024 | Change |\n",
    "|--------|------|------|--------|\n",
    "| Revenue | $120M | $150M | +25% |\n",
    "| Profit | $15M | $22M | +47% |\n",
    "| Employees | 450 | 520 | +16% |\n",
    "\n",
    "## Key Personnel\n",
    "- CEO: John Smith (john.smith@company.com)\n",
    "- CFO: Jane Doe (jane.doe@company.com)\n",
    "- CTO: Bob Wilson (bob.wilson@company.com)\n",
    "\n",
    "## Contact Information\n",
    "Address: 123 Business St, Tech City, TC 12345\n",
    "Phone: +1-555-0123\n",
    "Website: www.company.com\n",
    "\"\"\"\n",
    "\n",
    "# Create sample document for testing\n",
    "sample_path = Path(\"sample_report.md\")\n",
    "with open(sample_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(sample_text)\n",
    "\n",
    "# Test parser\n",
    "parser = DocumentParser()\n",
    "doc_content = parser.parse(sample_path)\n",
    "\n",
    "print(\"📄 Document Parsing Results:\")\n",
    "print(f\"Title: {doc_content.title}\")\n",
    "print(f\"Text length: {len(doc_content.text)} characters\")\n",
    "print(f\"Metadata: {doc_content.metadata}\")\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc57a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Schema Definition - Structured Output Models\n",
    "# Schema 定義 - 使用 Pydantic 定義結構化輸出格式\n",
    "\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional, Dict, Any\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    \"\"\"Contact information structure\"\"\"\n",
    "\n",
    "    name: Optional[str] = None\n",
    "    email: Optional[str] = None\n",
    "    phone: Optional[str] = None\n",
    "    title: Optional[str] = None\n",
    "\n",
    "    @validator(\"email\")\n",
    "    def validate_email(cls, v):\n",
    "        if v and \"@\" not in v:\n",
    "            raise ValueError(\"Invalid email format\")\n",
    "        return v\n",
    "\n",
    "\n",
    "class FinancialMetric(BaseModel):\n",
    "    \"\"\"Financial metric with value and unit\"\"\"\n",
    "\n",
    "    name: str\n",
    "    value: float\n",
    "    unit: str = \"USD\"\n",
    "    period: Optional[str] = None\n",
    "\n",
    "\n",
    "class CompanyInfo(BaseModel):\n",
    "    \"\"\"Company information schema\"\"\"\n",
    "\n",
    "    company_name: Optional[str] = None\n",
    "    industry: Optional[str] = None\n",
    "    address: Optional[str] = None\n",
    "    phone: Optional[str] = None\n",
    "    website: Optional[str] = None\n",
    "    employees: Optional[int] = None\n",
    "\n",
    "\n",
    "class DocumentSummary(BaseModel):\n",
    "    \"\"\"Complete document extraction schema\"\"\"\n",
    "\n",
    "    document_type: str = Field(\n",
    "        ...,\n",
    "        description=\"Type of document (e.g., 'annual_report', 'contract', 'resume')\",\n",
    "    )\n",
    "    title: Optional[str] = None\n",
    "    summary: str = Field(..., description=\"Brief summary of document content\")\n",
    "\n",
    "    # Entities\n",
    "    contacts: List[ContactInfo] = Field(\n",
    "        default_factory=list, description=\"People mentioned in document\"\n",
    "    )\n",
    "    companies: List[CompanyInfo] = Field(\n",
    "        default_factory=list, description=\"Companies mentioned\"\n",
    "    )\n",
    "    financial_metrics: List[FinancialMetric] = Field(\n",
    "        default_factory=list, description=\"Financial data\"\n",
    "    )\n",
    "\n",
    "    # Metadata\n",
    "    key_dates: List[str] = Field(\n",
    "        default_factory=list, description=\"Important dates mentioned\"\n",
    "    )\n",
    "    key_topics: List[str] = Field(\n",
    "        default_factory=list, description=\"Main topics/themes\"\n",
    "    )\n",
    "    confidence_score: float = Field(\n",
    "        default=0.0, ge=0.0, le=1.0, description=\"Extraction confidence\"\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"document_type\": \"annual_report\",\n",
    "                \"title\": \"Company Annual Report 2024\",\n",
    "                \"summary\": \"Annual financial performance report showing 25% revenue growth\",\n",
    "                \"contacts\": [\n",
    "                    {\n",
    "                        \"name\": \"John Smith\",\n",
    "                        \"title\": \"CEO\",\n",
    "                        \"email\": \"john.smith@company.com\",\n",
    "                    }\n",
    "                ],\n",
    "                \"companies\": [{\"company_name\": \"TechCorp\", \"industry\": \"Technology\"}],\n",
    "                \"financial_metrics\": [\n",
    "                    {\n",
    "                        \"name\": \"Revenue\",\n",
    "                        \"value\": 150000000,\n",
    "                        \"unit\": \"USD\",\n",
    "                        \"period\": \"2024\",\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "# Contract-specific schema\n",
    "class ContractClause(BaseModel):\n",
    "    \"\"\"Contract clause structure\"\"\"\n",
    "\n",
    "    clause_type: str  # e.g., \"payment_terms\", \"termination\", \"liability\"\n",
    "    content: str\n",
    "    importance: str = \"medium\"  # low, medium, high, critical\n",
    "\n",
    "\n",
    "class ContractInfo(BaseModel):\n",
    "    \"\"\"Contract document schema\"\"\"\n",
    "\n",
    "    contract_type: str  # e.g., \"service_agreement\", \"employment\", \"NDA\"\n",
    "    parties: List[str] = Field(default_factory=list)\n",
    "    effective_date: Optional[str] = None\n",
    "    expiration_date: Optional[str] = None\n",
    "    contract_value: Optional[float] = None\n",
    "    currency: str = \"USD\"\n",
    "    key_clauses: List[ContractClause] = Field(default_factory=list)\n",
    "    obligations: List[str] = Field(default_factory=list)\n",
    "    risks: List[str] = Field(default_factory=list)\n",
    "\n",
    "\n",
    "print(\"✅ Schema definitions created successfully\")\n",
    "print(\"Available schemas: DocumentSummary, ContractInfo, ContactInfo, FinancialMetric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab8ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. LLM Extraction Engine - Structured Information Extraction\n",
    "# LLM 抽取引擎 - 結構化資訊抽取與提示工程\n",
    "\n",
    "import json\n",
    "import re\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    ")\n",
    "import torch\n",
    "\n",
    "\n",
    "class LLMExtractor:\n",
    "    \"\"\"LLM-based information extraction engine\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, model_name: str = \"microsoft/DialoGPT-medium\", use_4bit: bool = True\n",
    "    ):\n",
    "        \"\"\"Initialize with low-VRAM friendly settings\"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # Configure quantization for low VRAM\n",
    "        if use_4bit and torch.cuda.is_available():\n",
    "            bnb_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_compute_dtype=torch.float16,\n",
    "                bnb_4bit_quant_type=\"nf4\",\n",
    "                bnb_4bit_use_double_quant=True,\n",
    "            )\n",
    "        else:\n",
    "            bnb_config = None\n",
    "\n",
    "        # Load model with device mapping for multi-GPU or CPU fallback\n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_name, padding_side=\"left\"\n",
    "            )\n",
    "            if self.tokenizer.pad_token is None:\n",
    "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                quantization_config=bnb_config,\n",
    "                device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "                torch_dtype=(\n",
    "                    torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "                ),\n",
    "                low_cpu_mem_usage=True,\n",
    "            )\n",
    "\n",
    "            print(f\"✅ Model loaded: {model_name} on {self.device}\")\n",
    "            if torch.cuda.is_available():\n",
    "                print(f\"💾 VRAM usage: {torch.cuda.memory_allocated() / 1e9:.2f}GB\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading model: {e}\")\n",
    "            print(\"💡 Falling back to simpler extraction methods...\")\n",
    "            self.model = None\n",
    "            self.tokenizer = None\n",
    "\n",
    "    def extract_structured_info(self, text: str, schema_type: str = \"general\") -> Dict:\n",
    "        \"\"\"Extract structured information based on schema type\"\"\"\n",
    "\n",
    "        # Create extraction prompt based on schema\n",
    "        if schema_type == \"general\":\n",
    "            prompt = self._create_general_extraction_prompt(text)\n",
    "            return self._extract_with_prompt(prompt, DocumentSummary)\n",
    "        elif schema_type == \"contract\":\n",
    "            prompt = self._create_contract_extraction_prompt(text)\n",
    "            return self._extract_with_prompt(prompt, ContractInfo)\n",
    "        else:\n",
    "            return self._fallback_extraction(text)\n",
    "\n",
    "    def _create_general_extraction_prompt(self, text: str) -> str:\n",
    "        \"\"\"Create prompt for general document extraction\"\"\"\n",
    "        return f\"\"\"\n",
    "Analyze the following document and extract structured information in JSON format.\n",
    "\n",
    "Document text:\n",
    "{text[:2000]}...\n",
    "\n",
    "Extract the following information:\n",
    "1. Document type (e.g., annual_report, contract, resume, email)\n",
    "2. Title or subject\n",
    "3. Brief summary (1-2 sentences)\n",
    "4. People mentioned (name, title, email, phone)\n",
    "5. Companies mentioned (name, industry, contact info)\n",
    "6. Financial metrics (amounts, percentages, revenues)\n",
    "7. Important dates\n",
    "8. Key topics/themes\n",
    "\n",
    "Return only valid JSON in this exact format:\n",
    "{{\n",
    "    \"document_type\": \"document_type_here\",\n",
    "    \"title\": \"title_here\",\n",
    "    \"summary\": \"summary_here\",\n",
    "    \"contacts\": [\n",
    "        {{\"name\": \"John Doe\", \"title\": \"CEO\", \"email\": \"john@company.com\", \"phone\": \"+1-555-0123\"}}\n",
    "    ],\n",
    "    \"companies\": [\n",
    "        {{\"company_name\": \"TechCorp\", \"industry\": \"Technology\", \"website\": \"www.techcorp.com\"}}\n",
    "    ],\n",
    "    \"financial_metrics\": [\n",
    "        {{\"name\": \"Revenue\", \"value\": 150000000, \"unit\": \"USD\", \"period\": \"2024\"}}\n",
    "    ],\n",
    "    \"key_dates\": [\"2024-01-01\", \"Q2 2024\"],\n",
    "    \"key_topics\": [\"growth\", \"expansion\", \"partnership\"],\n",
    "    \"confidence_score\": 0.8\n",
    "}}\n",
    "\n",
    "JSON:\n",
    "\"\"\"\n",
    "\n",
    "    def _create_contract_extraction_prompt(self, text: str) -> str:\n",
    "        \"\"\"Create prompt for contract-specific extraction\"\"\"\n",
    "        return f\"\"\"\n",
    "Analyze this contract document and extract key legal information in JSON format.\n",
    "\n",
    "Contract text:\n",
    "{text[:2000]}...\n",
    "\n",
    "Extract:\n",
    "1. Contract type (service_agreement, employment, NDA, etc.)\n",
    "2. Parties involved\n",
    "3. Effective and expiration dates\n",
    "4. Contract value and currency\n",
    "5. Key clauses (payment terms, termination, liability, etc.)\n",
    "6. Obligations for each party\n",
    "7. Potential risks or red flags\n",
    "\n",
    "Return valid JSON:\n",
    "{{\n",
    "    \"contract_type\": \"service_agreement\",\n",
    "    \"parties\": [\"Company A\", \"Company B\"],\n",
    "    \"effective_date\": \"2024-01-01\",\n",
    "    \"expiration_date\": \"2024-12-31\",\n",
    "    \"contract_value\": 100000,\n",
    "    \"currency\": \"USD\",\n",
    "    \"key_clauses\": [\n",
    "        {{\"clause_type\": \"payment_terms\", \"content\": \"Payment due within 30 days\", \"importance\": \"high\"}}\n",
    "    ],\n",
    "    \"obligations\": [\"Company A must deliver software\", \"Company B must pay fees\"],\n",
    "    \"risks\": [\"No penalty for late delivery\", \"Unclear IP ownership\"]\n",
    "}}\n",
    "\n",
    "JSON:\n",
    "\"\"\"\n",
    "\n",
    "    def _extract_with_prompt(self, prompt: str, schema_class) -> Dict:\n",
    "        \"\"\"Extract information using LLM with structured prompt\"\"\"\n",
    "\n",
    "        if self.model is None:\n",
    "            return self._fallback_extraction(prompt)\n",
    "\n",
    "        try:\n",
    "            # Tokenize and generate\n",
    "            inputs = self.tokenizer(\n",
    "                prompt, return_tensors=\"pt\", truncation=True, max_length=1024\n",
    "            )\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=512,\n",
    "                    temperature=0.1,  # Low temperature for structured output\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id,\n",
    "                    num_return_sequences=1,\n",
    "                )\n",
    "\n",
    "            # Decode response\n",
    "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            json_part = response[len(prompt) :].strip()\n",
    "\n",
    "            # Extract JSON from response\n",
    "            json_match = re.search(r\"\\{.*\\}\", json_part, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group()\n",
    "                try:\n",
    "                    extracted_data = json.loads(json_str)\n",
    "                    # Validate against schema\n",
    "                    validated = schema_class(**extracted_data)\n",
    "                    return validated.dict()\n",
    "                except (json.JSONDecodeError, ValueError) as e:\n",
    "                    print(f\"⚠️ JSON parsing error: {e}\")\n",
    "                    return self._fallback_extraction(prompt)\n",
    "            else:\n",
    "                return self._fallback_extraction(prompt)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Extraction error: {e}\")\n",
    "            return self._fallback_extraction(prompt)\n",
    "\n",
    "    def _fallback_extraction(self, text: str) -> Dict:\n",
    "        \"\"\"Fallback extraction using regex patterns\"\"\"\n",
    "        print(\"📋 Using fallback regex-based extraction...\")\n",
    "\n",
    "        # Simple regex-based extraction\n",
    "        emails = re.findall(\n",
    "            r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\", text\n",
    "        )\n",
    "        phones = re.findall(\n",
    "            r\"\\+?1?-?\\s?\\(?[0-9]{3}\\)?[-.\\s]?[0-9]{3}[-.\\s]?[0-9]{4}\", text\n",
    "        )\n",
    "        dates = re.findall(\n",
    "            r\"\\b\\d{4}[-/]\\d{2}[-/]\\d{2}\\b|\\b\\d{1,2}[-/]\\d{1,2}[-/]\\d{4}\\b\", text\n",
    "        )\n",
    "        amounts = re.findall(r\"\\$\\s*(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)\", text)\n",
    "\n",
    "        # Extract potential names (capitalized words)\n",
    "        potential_names = re.findall(r\"\\b[A-Z][a-z]+ [A-Z][a-z]+\\b\", text)\n",
    "\n",
    "        return {\n",
    "            \"document_type\": \"unknown\",\n",
    "            \"title\": text.split(\"\\n\")[0][:100] if text else \"Unknown\",\n",
    "            \"summary\": text[:200] + \"...\" if len(text) > 200 else text,\n",
    "            \"contacts\": [{\"email\": email} for email in emails[:3]],\n",
    "            \"companies\": [],\n",
    "            \"financial_metrics\": [\n",
    "                {\"name\": \"Amount\", \"value\": float(amt.replace(\",\", \"\")), \"unit\": \"USD\"}\n",
    "                for amt in amounts[:3]\n",
    "            ],\n",
    "            \"key_dates\": dates[:5],\n",
    "            \"key_topics\": [\"document_analysis\"],\n",
    "            \"confidence_score\": 0.3,  # Low confidence for regex-based extraction\n",
    "        }\n",
    "\n",
    "\n",
    "# Initialize extractor with fallback-friendly model\n",
    "# 初始化抽取器（使用容錯模型）\n",
    "try:\n",
    "    # Try with smaller model first for testing\n",
    "    extractor = LLMExtractor(model_name=\"microsoft/DialoGPT-small\", use_4bit=True)\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Model loading failed: {e}\")\n",
    "    print(\"💡 Creating extractor with fallback mode...\")\n",
    "    extractor = LLMExtractor()\n",
    "\n",
    "# Test extraction on sample document\n",
    "# 測試文件抽取功能\n",
    "print(\"\\n🔍 Testing Information Extraction:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "extracted_info = extractor.extract_structured_info(sample_text, schema_type=\"general\")\n",
    "print(\"📊 Extracted Information:\")\n",
    "print(json.dumps(extracted_info, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Batch Processing Pipeline - Scalable Document Processing\n",
    "# 批量處理管線 - 可擴展的文件處理工作流\n",
    "\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import Generator\n",
    "\n",
    "\n",
    "class DocumentProcessingPipeline:\n",
    "    \"\"\"Scalable document processing pipeline with error handling\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, parser: DocumentParser, extractor: LLMExtractor, max_workers: int = 2\n",
    "    ):\n",
    "        self.parser = parser\n",
    "        self.extractor = extractor\n",
    "        self.max_workers = max_workers\n",
    "        self.results = []\n",
    "\n",
    "        # Setup logging\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def process_single_document(\n",
    "        self, file_path: Path, schema_type: str = \"general\"\n",
    "    ) -> Dict:\n",
    "        \"\"\"Process a single document through the full pipeline\"\"\"\n",
    "        try:\n",
    "            # Parse document\n",
    "            doc_content = self.parser.parse(file_path)\n",
    "\n",
    "            # Extract structured information\n",
    "            extracted_info = self.extractor.extract_structured_info(\n",
    "                doc_content.text, schema_type=schema_type\n",
    "            )\n",
    "\n",
    "            # Combine results\n",
    "            result = {\n",
    "                \"file_path\": str(file_path),\n",
    "                \"processing_time\": datetime.now().isoformat(),\n",
    "                \"document_metadata\": doc_content.metadata,\n",
    "                \"extracted_info\": extracted_info,\n",
    "                \"status\": \"success\",\n",
    "            }\n",
    "\n",
    "            # Add table information if available\n",
    "            if doc_content.tables:\n",
    "                result[\"tables_found\"] = len(doc_content.tables)\n",
    "                result[\"table_summaries\"] = [\n",
    "                    {\"rows\": len(table), \"columns\": len(table.columns)}\n",
    "                    for table in doc_content.tables\n",
    "                ]\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing {file_path}: {e}\")\n",
    "            return {\n",
    "                \"file_path\": str(file_path),\n",
    "                \"processing_time\": datetime.now().isoformat(),\n",
    "                \"error\": str(e),\n",
    "                \"status\": \"error\",\n",
    "            }\n",
    "\n",
    "    def process_batch(\n",
    "        self, file_paths: List[Path], schema_type: str = \"general\"\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Process multiple documents in parallel\"\"\"\n",
    "        results = []\n",
    "\n",
    "        # Sequential processing for memory management (can enable parallel if VRAM allows)\n",
    "        if self.max_workers == 1 or not torch.cuda.is_available():\n",
    "            # Sequential processing\n",
    "            for file_path in tqdm(file_paths, desc=\"Processing documents\"):\n",
    "                result = self.process_single_document(file_path, schema_type)\n",
    "                results.append(result)\n",
    "        else:\n",
    "            # Parallel processing (use with caution on GPU)\n",
    "            with concurrent.futures.ThreadPoolExecutor(\n",
    "                max_workers=self.max_workers\n",
    "            ) as executor:\n",
    "                future_to_file = {\n",
    "                    executor.submit(\n",
    "                        self.process_single_document, file_path, schema_type\n",
    "                    ): file_path\n",
    "                    for file_path in file_paths\n",
    "                }\n",
    "\n",
    "                for future in tqdm(\n",
    "                    concurrent.futures.as_completed(future_to_file),\n",
    "                    total=len(file_paths),\n",
    "                    desc=\"Processing documents\",\n",
    "                ):\n",
    "                    result = future.result()\n",
    "                    results.append(result)\n",
    "\n",
    "        self.results = results\n",
    "        return results\n",
    "\n",
    "    def export_results(self, output_path: Path, format: str = \"json\"):\n",
    "        \"\"\"Export processing results to file\"\"\"\n",
    "        if format == \"json\":\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(self.results, f, indent=2, ensure_ascii=False)\n",
    "        elif format == \"csv\":\n",
    "            # Flatten results for CSV export\n",
    "            flattened = []\n",
    "            for result in self.results:\n",
    "                if result[\"status\"] == \"success\":\n",
    "                    flat_result = {\n",
    "                        \"file_path\": result[\"file_path\"],\n",
    "                        \"processing_time\": result[\"processing_time\"],\n",
    "                        \"document_type\": result[\"extracted_info\"].get(\n",
    "                            \"document_type\", \"\"\n",
    "                        ),\n",
    "                        \"title\": result[\"extracted_info\"].get(\"title\", \"\"),\n",
    "                        \"summary\": result[\"extracted_info\"].get(\"summary\", \"\"),\n",
    "                        \"contacts_count\": len(\n",
    "                            result[\"extracted_info\"].get(\"contacts\", [])\n",
    "                        ),\n",
    "                        \"companies_count\": len(\n",
    "                            result[\"extracted_info\"].get(\"companies\", [])\n",
    "                        ),\n",
    "                        \"confidence_score\": result[\"extracted_info\"].get(\n",
    "                            \"confidence_score\", 0\n",
    "                        ),\n",
    "                    }\n",
    "                else:\n",
    "                    flat_result = {\n",
    "                        \"file_path\": result[\"file_path\"],\n",
    "                        \"processing_time\": result[\"processing_time\"],\n",
    "                        \"error\": result.get(\"error\", \"\"),\n",
    "                        \"status\": result[\"status\"],\n",
    "                    }\n",
    "                flattened.append(flat_result)\n",
    "\n",
    "            df = pd.DataFrame(flattened)\n",
    "            df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "        print(f\"✅ Results exported to: {output_path}\")\n",
    "\n",
    "    def get_processing_stats(self) -> Dict:\n",
    "        \"\"\"Get processing statistics\"\"\"\n",
    "        if not self.results:\n",
    "            return {\"message\": \"No results to analyze\"}\n",
    "\n",
    "        total_docs = len(self.results)\n",
    "        successful = sum(1 for r in self.results if r[\"status\"] == \"success\")\n",
    "        failed = total_docs - successful\n",
    "\n",
    "        # Calculate confidence score distribution\n",
    "        confidence_scores = [\n",
    "            r[\"extracted_info\"][\"confidence_score\"]\n",
    "            for r in self.results\n",
    "            if r[\"status\"] == \"success\" and \"confidence_score\" in r[\"extracted_info\"]\n",
    "        ]\n",
    "\n",
    "        avg_confidence = (\n",
    "            sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"total_documents\": total_docs,\n",
    "            \"successful\": successful,\n",
    "            \"failed\": failed,\n",
    "            \"success_rate\": successful / total_docs * 100,\n",
    "            \"average_confidence\": avg_confidence,\n",
    "            \"confidence_distribution\": {\n",
    "                \"high (>0.8)\": sum(1 for c in confidence_scores if c > 0.8),\n",
    "                \"medium (0.5-0.8)\": sum(\n",
    "                    1 for c in confidence_scores if 0.5 <= c <= 0.8\n",
    "                ),\n",
    "                \"low (<0.5)\": sum(1 for c in confidence_scores if c < 0.5),\n",
    "            },\n",
    "        }\n",
    "\n",
    "\n",
    "# Create processing pipeline\n",
    "# 創建處理管線\n",
    "pipeline = DocumentProcessingPipeline(\n",
    "    parser=parser,\n",
    "    extractor=extractor,\n",
    "    max_workers=1,  # Sequential processing for VRAM safety\n",
    ")\n",
    "\n",
    "# Create additional sample documents for batch testing\n",
    "# 創建額外範例文件以測試批量處理\n",
    "sample_files = []\n",
    "\n",
    "# Sample contract document\n",
    "contract_text = \"\"\"\n",
    "SERVICE AGREEMENT\n",
    "\n",
    "This Service Agreement (\"Agreement\") is entered into on January 1, 2024,\n",
    "between TechCorp Inc. (\"Provider\") and Business Solutions Ltd. (\"Client\").\n",
    "\n",
    "PARTIES:\n",
    "- Provider: TechCorp Inc., 123 Tech Street, Silicon Valley, CA 94000\n",
    "- Client: Business Solutions Ltd., 456 Business Ave, New York, NY 10001\n",
    "\n",
    "SCOPE OF WORK:\n",
    "The Provider agrees to deliver custom software development services including:\n",
    "1. Web application development\n",
    "2. Mobile app development\n",
    "3. System integration\n",
    "4. Technical support and maintenance\n",
    "\n",
    "PAYMENT TERMS:\n",
    "- Total contract value: $250,000 USD\n",
    "- Payment schedule: 50% upfront, 25% at milestone 1, 25% upon completion\n",
    "- Invoices due within 30 days of receipt\n",
    "\n",
    "TIMELINE:\n",
    "- Effective Date: January 1, 2024\n",
    "- Project Duration: 12 months\n",
    "- Completion Date: December 31, 2024\n",
    "\n",
    "TERMINATION:\n",
    "Either party may terminate this agreement with 30 days written notice.\n",
    "Client retains rights to completed work upon termination.\n",
    "\n",
    "CONTACTS:\n",
    "- Provider Contact: John Tech (john.tech@techcorp.com, +1-555-TECH)\n",
    "- Client Contact: Jane Business (jane.business@bizsolve.com, +1-555-BUSI)\n",
    "\"\"\"\n",
    "\n",
    "contract_path = Path(\"sample_contract.txt\")\n",
    "with open(contract_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(contract_text)\n",
    "sample_files.append(contract_path)\n",
    "\n",
    "# Sample resume document\n",
    "resume_text = \"\"\"\n",
    "ALICE CHEN\n",
    "Software Engineer\n",
    "\n",
    "Contact Information:\n",
    "Email: alice.chen@email.com\n",
    "Phone: +1-555-0199\n",
    "LinkedIn: linkedin.com/in/alicechen\n",
    "Location: San Francisco, CA\n",
    "\n",
    "PROFESSIONAL SUMMARY:\n",
    "Experienced software engineer with 8+ years in full-stack development.\n",
    "Specialized in Python, JavaScript, and cloud technologies.\n",
    "\n",
    "WORK EXPERIENCE:\n",
    "\n",
    "Senior Software Engineer | Meta | 2020-2024\n",
    "- Led development of microservices handling 10M+ daily requests\n",
    "- Reduced API response time by 40% through optimization\n",
    "- Mentored 5 junior developers\n",
    "\n",
    "Software Engineer | Google | 2018-2020\n",
    "- Developed machine learning pipelines for search algorithms\n",
    "- Collaborated with cross-functional teams of 20+ members\n",
    "- Contributed to open-source TensorFlow projects\n",
    "\n",
    "Junior Developer | Startup Co | 2016-2018\n",
    "- Built web applications using React and Node.js\n",
    "- Implemented CI/CD pipelines reducing deployment time by 60%\n",
    "\n",
    "EDUCATION:\n",
    "Master of Science in Computer Science | Stanford University | 2016\n",
    "Bachelor of Science in Software Engineering | UC Berkeley | 2014\n",
    "\n",
    "SKILLS:\n",
    "- Programming: Python, JavaScript, Java, Go, SQL\n",
    "- Frameworks: React, Django, Flask, Node.js\n",
    "- Cloud: AWS, GCP, Docker, Kubernetes\n",
    "- Databases: PostgreSQL, MongoDB, Redis\n",
    "\n",
    "CERTIFICATIONS:\n",
    "- AWS Solutions Architect Professional (2023)\n",
    "- Google Cloud Professional Data Engineer (2022)\n",
    "\"\"\"\n",
    "\n",
    "resume_path = Path(\"sample_resume.txt\")\n",
    "with open(resume_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(resume_text)\n",
    "sample_files.append(resume_path)\n",
    "\n",
    "# Test batch processing\n",
    "# 測試批量處理\n",
    "print(\"\\n🔄 Testing Batch Processing Pipeline:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Process documents with different schema types\n",
    "results = []\n",
    "for file_path in sample_files:\n",
    "    if \"contract\" in file_path.name:\n",
    "        result = pipeline.process_single_document(file_path, schema_type=\"contract\")\n",
    "    else:\n",
    "        result = pipeline.process_single_document(file_path, schema_type=\"general\")\n",
    "    results.append(result)\n",
    "\n",
    "# Add original sample document\n",
    "results.append(pipeline.process_single_document(sample_path, schema_type=\"general\"))\n",
    "\n",
    "pipeline.results = results\n",
    "\n",
    "# Display processing statistics\n",
    "stats = pipeline.get_processing_stats()\n",
    "print(\"\\n📊 Processing Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Export results\n",
    "output_path = Path(\"extraction_results.json\")\n",
    "pipeline.export_results(output_path, format=\"json\")\n",
    "\n",
    "print(f\"\\n✅ Processed {len(sample_files)+1} documents successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bac56d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Quality Assessment Module - Extraction Accuracy Evaluation\n",
    "# 品質評估模組 - 抽取準確率評估\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import difflib\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class ExtractionEvaluator:\n",
    "    \"\"\"Evaluate extraction quality against ground truth\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.evaluation_results = []\n",
    "\n",
    "    def evaluate_extraction(self, extracted: Dict, ground_truth: Dict) -> Dict:\n",
    "        \"\"\"Evaluate extraction against ground truth data\"\"\"\n",
    "\n",
    "        results = {\n",
    "            \"overall_accuracy\": 0.0,\n",
    "            \"field_accuracy\": {},\n",
    "            \"entity_metrics\": {},\n",
    "            \"confidence_correlation\": 0.0,\n",
    "        }\n",
    "\n",
    "        # Field-level accuracy\n",
    "        field_scores = []\n",
    "        for field in ground_truth.keys():\n",
    "            if field in extracted:\n",
    "                if isinstance(ground_truth[field], str):\n",
    "                    # Text similarity for string fields\n",
    "                    similarity = difflib.SequenceMatcher(\n",
    "                        None,\n",
    "                        str(extracted[field]).lower(),\n",
    "                        str(ground_truth[field]).lower(),\n",
    "                    ).ratio()\n",
    "                    field_scores.append(similarity)\n",
    "                    results[\"field_accuracy\"][field] = similarity\n",
    "                elif isinstance(ground_truth[field], list):\n",
    "                    # List overlap for list fields\n",
    "                    if len(ground_truth[field]) == 0:\n",
    "                        overlap = 1.0 if len(extracted[field]) == 0 else 0.0\n",
    "                    else:\n",
    "                        extracted_set = set(str(x).lower() for x in extracted[field])\n",
    "                        ground_truth_set = set(\n",
    "                            str(x).lower() for x in ground_truth[field]\n",
    "                        )\n",
    "                        overlap = len(extracted_set & ground_truth_set) / len(\n",
    "                            ground_truth_set\n",
    "                        )\n",
    "                    field_scores.append(overlap)\n",
    "                    results[\"field_accuracy\"][field] = overlap\n",
    "                else:\n",
    "                    # Exact match for other types\n",
    "                    exact_match = (\n",
    "                        1.0 if extracted[field] == ground_truth[field] else 0.0\n",
    "                    )\n",
    "                    field_scores.append(exact_match)\n",
    "                    results[\"field_accuracy\"][field] = exact_match\n",
    "            else:\n",
    "                field_scores.append(0.0)\n",
    "                results[\"field_accuracy\"][field] = 0.0\n",
    "\n",
    "        results[\"overall_accuracy\"] = (\n",
    "            sum(field_scores) / len(field_scores) if field_scores else 0.0\n",
    "        )\n",
    "\n",
    "        # Entity-level evaluation (contacts, companies)\n",
    "        if \"contacts\" in ground_truth and \"contacts\" in extracted:\n",
    "            results[\"entity_metrics\"][\"contacts\"] = self._evaluate_entities(\n",
    "                extracted[\"contacts\"], ground_truth[\"contacts\"]\n",
    "            )\n",
    "\n",
    "        if \"companies\" in ground_truth and \"companies\" in extracted:\n",
    "            results[\"entity_metrics\"][\"companies\"] = self._evaluate_entities(\n",
    "                extracted[\"companies\"], ground_truth[\"companies\"]\n",
    "            )\n",
    "\n",
    "        # Confidence correlation (if available)\n",
    "        if \"confidence_score\" in extracted:\n",
    "            results[\"confidence_correlation\"] = min(\n",
    "                extracted[\"confidence_score\"] * results[\"overall_accuracy\"], 1.0\n",
    "            )\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _evaluate_entities(\n",
    "        self, extracted_entities: List[Dict], ground_truth_entities: List[Dict]\n",
    "    ) -> Dict:\n",
    "        \"\"\"Evaluate entity extraction (precision, recall, F1)\"\"\"\n",
    "        if not ground_truth_entities:\n",
    "            return (\n",
    "                {\"precision\": 1.0, \"recall\": 1.0, \"f1\": 1.0}\n",
    "                if not extracted_entities\n",
    "                else {\"precision\": 0.0, \"recall\": 1.0, \"f1\": 0.0}\n",
    "            )\n",
    "\n",
    "        if not extracted_entities:\n",
    "            return {\"precision\": 1.0, \"recall\": 0.0, \"f1\": 0.0}\n",
    "\n",
    "        # Simple name-based matching for demonstration\n",
    "        extracted_names = set()\n",
    "        ground_truth_names = set()\n",
    "\n",
    "        for entity in extracted_entities:\n",
    "            if \"name\" in entity and entity[\"name\"]:\n",
    "                extracted_names.add(entity[\"name\"].lower().strip())\n",
    "\n",
    "        for entity in ground_truth_entities:\n",
    "            if \"name\" in entity and entity[\"name\"]:\n",
    "                ground_truth_names.add(entity[\"name\"].lower().strip())\n",
    "\n",
    "        if not ground_truth_names:\n",
    "            precision = 1.0 if not extracted_names else 0.0\n",
    "            recall = 1.0\n",
    "            f1 = 1.0 if precision == 1.0 else 0.0\n",
    "        else:\n",
    "            true_positives = len(extracted_names & ground_truth_names)\n",
    "            precision = (\n",
    "                true_positives / len(extracted_names) if extracted_names else 0.0\n",
    "            )\n",
    "            recall = true_positives / len(ground_truth_names)\n",
    "            f1 = (\n",
    "                2 * (precision * recall) / (precision + recall)\n",
    "                if (precision + recall) > 0\n",
    "                else 0.0\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "            \"true_positives\": len(extracted_names & ground_truth_names),\n",
    "            \"extracted_count\": len(extracted_names),\n",
    "            \"ground_truth_count\": len(ground_truth_names),\n",
    "        }\n",
    "\n",
    "    def create_evaluation_report(self, evaluations: List[Dict]) -> Dict:\n",
    "        \"\"\"Create comprehensive evaluation report\"\"\"\n",
    "        if not evaluations:\n",
    "            return {\"error\": \"No evaluations provided\"}\n",
    "\n",
    "        # Aggregate metrics\n",
    "        overall_accuracies = [e[\"overall_accuracy\"] for e in evaluations]\n",
    "\n",
    "        report = {\n",
    "            \"summary\": {\n",
    "                \"total_evaluations\": len(evaluations),\n",
    "                \"average_accuracy\": sum(overall_accuracies) / len(overall_accuracies),\n",
    "                \"min_accuracy\": min(overall_accuracies),\n",
    "                \"max_accuracy\": max(overall_accuracies),\n",
    "                \"std_accuracy\": (\n",
    "                    sum(\n",
    "                        (x - sum(overall_accuracies) / len(overall_accuracies)) ** 2\n",
    "                        for x in overall_accuracies\n",
    "                    )\n",
    "                    / len(overall_accuracies)\n",
    "                )\n",
    "                ** 0.5,\n",
    "            },\n",
    "            \"field_performance\": {},\n",
    "            \"entity_performance\": {},\n",
    "            \"recommendations\": [],\n",
    "        }\n",
    "\n",
    "        # Field-level performance\n",
    "        all_fields = set()\n",
    "        for eval_result in evaluations:\n",
    "            all_fields.update(eval_result[\"field_accuracy\"].keys())\n",
    "\n",
    "        for field in all_fields:\n",
    "            field_scores = [e[\"field_accuracy\"].get(field, 0.0) for e in evaluations]\n",
    "            report[\"field_performance\"][field] = {\n",
    "                \"average\": sum(field_scores) / len(field_scores),\n",
    "                \"min\": min(field_scores),\n",
    "                \"max\": max(field_scores),\n",
    "            }\n",
    "\n",
    "        # Entity-level performance\n",
    "        for entity_type in [\"contacts\", \"companies\"]:\n",
    "            entity_metrics = []\n",
    "            for eval_result in evaluations:\n",
    "                if entity_type in eval_result[\"entity_metrics\"]:\n",
    "                    entity_metrics.append(eval_result[\"entity_metrics\"][entity_type])\n",
    "\n",
    "            if entity_metrics:\n",
    "                avg_precision = sum(m[\"precision\"] for m in entity_metrics) / len(\n",
    "                    entity_metrics\n",
    "                )\n",
    "                avg_recall = sum(m[\"recall\"] for m in entity_metrics) / len(\n",
    "                    entity_metrics\n",
    "                )\n",
    "                avg_f1 = sum(m[\"f1\"] for m in entity_metrics) / len(entity_metrics)\n",
    "\n",
    "                report[\"entity_performance\"][entity_type] = {\n",
    "                    \"precision\": avg_precision,\n",
    "                    \"recall\": avg_recall,\n",
    "                    \"f1\": avg_f1,\n",
    "                }\n",
    "\n",
    "        # Generate recommendations\n",
    "        if report[\"summary\"][\"average_accuracy\"] < 0.7:\n",
    "            report[\"recommendations\"].append(\n",
    "                \"Overall accuracy is low. Consider improving prompts or using a larger model.\"\n",
    "            )\n",
    "\n",
    "        for field, performance in report[\"field_performance\"].items():\n",
    "            if performance[\"average\"] < 0.5:\n",
    "                report[\"recommendations\"].append(\n",
    "                    f\"Field '{field}' shows poor extraction accuracy. Review extraction logic.\"\n",
    "                )\n",
    "\n",
    "        return report\n",
    "\n",
    "\n",
    "# Test evaluation with sample data\n",
    "# 測試評估功能\n",
    "evaluator = ExtractionEvaluator()\n",
    "\n",
    "# Create ground truth for sample document\n",
    "ground_truth_sample = {\n",
    "    \"document_type\": \"annual_report\",\n",
    "    \"title\": \"Company Annual Report 2024\",\n",
    "    \"summary\": \"Annual financial performance report showing growth\",\n",
    "    \"contacts\": [\n",
    "        {\"name\": \"John Smith\", \"email\": \"john.smith@company.com\", \"title\": \"CEO\"},\n",
    "        {\"name\": \"Jane Doe\", \"email\": \"jane.doe@company.com\", \"title\": \"CFO\"},\n",
    "        {\"name\": \"Bob Wilson\", \"email\": \"bob.wilson@company.com\", \"title\": \"CTO\"},\n",
    "    ],\n",
    "    \"companies\": [{\"company_name\": \"TechCorp\", \"industry\": \"Technology\"}],\n",
    "    \"financial_metrics\": [\n",
    "        {\"name\": \"Revenue\", \"value\": 150000000, \"unit\": \"USD\", \"period\": \"2024\"},\n",
    "        {\"name\": \"Profit\", \"value\": 22000000, \"unit\": \"USD\", \"period\": \"2024\"},\n",
    "    ],\n",
    "    \"key_dates\": [\"2024\"],\n",
    "    \"key_topics\": [\"growth\", \"revenue\", \"partnership\"],\n",
    "    \"confidence_score\": 0.8,\n",
    "}\n",
    "\n",
    "# Evaluate extraction\n",
    "evaluation_result = evaluator.evaluate_extraction(extracted_info, ground_truth_sample)\n",
    "\n",
    "print(\"\\n🎯 Extraction Quality Evaluation:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Overall Accuracy: {evaluation_result['overall_accuracy']:.2f}\")\n",
    "print(\"\\nField-level Accuracy:\")\n",
    "for field, score in evaluation_result[\"field_accuracy\"].items():\n",
    "    print(f\"  {field}: {score:.2f}\")\n",
    "\n",
    "if evaluation_result[\"entity_metrics\"]:\n",
    "    print(\"\\nEntity Extraction Metrics:\")\n",
    "    for entity_type, metrics in evaluation_result[\"entity_metrics\"].items():\n",
    "        print(f\"  {entity_type}:\")\n",
    "        print(f\"    Precision: {metrics['precision']:.2f}\")\n",
    "        print(f\"    Recall: {metrics['recall']:.2f}\")\n",
    "        print(f\"    F1-Score: {metrics['f1']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c910d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Real-world Use Cases - Contract, Resume, and Academic Paper Analysis\n",
    "# 實戰案例 - 合約、簡歷、學術論文分析\n",
    "\n",
    "\n",
    "class SpecializedExtractors:\n",
    "    \"\"\"Specialized extractors for different document types\"\"\"\n",
    "\n",
    "    def __init__(self, base_extractor: LLMExtractor):\n",
    "        self.base_extractor = base_extractor\n",
    "\n",
    "    def extract_resume_info(self, text: str) -> Dict:\n",
    "        \"\"\"Extract structured information from resume/CV\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "Extract professional information from this resume/CV in JSON format:\n",
    "\n",
    "{text[:1500]}...\n",
    "\n",
    "Extract:\n",
    "1. Personal information (name, email, phone, location)\n",
    "2. Professional summary/objective\n",
    "3. Work experience (company, role, duration, achievements)\n",
    "4. Education (degree, school, year)\n",
    "5. Skills (technical, soft skills)\n",
    "6. Certifications\n",
    "7. Years of experience (total)\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "    \"personal_info\": {{\n",
    "        \"name\": \"Full Name\",\n",
    "        \"email\": \"email@domain.com\",\n",
    "        \"phone\": \"+1-555-0123\",\n",
    "        \"location\": \"City, State\"\n",
    "    }},\n",
    "    \"professional_summary\": \"Brief summary...\",\n",
    "    \"work_experience\": [\n",
    "        {{\n",
    "            \"company\": \"Company Name\",\n",
    "            \"role\": \"Job Title\",\n",
    "            \"duration\": \"2020-2024\",\n",
    "            \"achievements\": [\"Achievement 1\", \"Achievement 2\"]\n",
    "        }}\n",
    "    ],\n",
    "    \"education\": [\n",
    "        {{\n",
    "            \"degree\": \"Master of Science\",\n",
    "            \"field\": \"Computer Science\",\n",
    "            \"school\": \"University Name\",\n",
    "            \"year\": \"2016\"\n",
    "        }}\n",
    "    ],\n",
    "    \"skills\": {{\n",
    "        \"technical\": [\"Python\", \"JavaScript\"],\n",
    "        \"soft\": [\"Leadership\", \"Communication\"]\n",
    "    }},\n",
    "    \"certifications\": [\"AWS Certified\", \"Google Cloud\"],\n",
    "    \"total_experience_years\": 8\n",
    "}}\n",
    "\n",
    "JSON:\n",
    "\"\"\"\n",
    "        return self.base_extractor._extract_with_prompt(prompt, DocumentSummary)\n",
    "\n",
    "    def extract_academic_paper_info(self, text: str) -> Dict:\n",
    "        \"\"\"Extract information from academic papers\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "Extract academic paper information in JSON format:\n",
    "\n",
    "{text[:1500]}...\n",
    "\n",
    "Extract:\n",
    "1. Title and abstract\n",
    "2. Authors and affiliations\n",
    "3. Keywords\n",
    "4. Methodology/approach\n",
    "5. Key findings/results\n",
    "6. References count (estimate)\n",
    "7. Research field/domain\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "    \"title\": \"Paper Title\",\n",
    "    \"abstract\": \"Abstract text...\",\n",
    "    \"authors\": [\n",
    "        {{\"name\": \"Author Name\", \"affiliation\": \"University Name\"}}\n",
    "    ],\n",
    "    \"keywords\": [\"keyword1\", \"keyword2\"],\n",
    "    \"methodology\": \"Research approach description\",\n",
    "    \"key_findings\": [\"Finding 1\", \"Finding 2\"],\n",
    "    \"research_field\": \"Computer Science\",\n",
    "    \"estimated_references\": 25,\n",
    "    \"publication_info\": {{\n",
    "        \"journal\": \"Journal Name\",\n",
    "        \"year\": \"2024\",\n",
    "        \"volume\": \"12\",\n",
    "        \"pages\": \"1-15\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "JSON:\n",
    "\"\"\"\n",
    "        return self.base_extractor._extract_with_prompt(prompt, DocumentSummary)\n",
    "\n",
    "\n",
    "# Initialize specialized extractors\n",
    "# 初始化專門抽取器\n",
    "specialized = SpecializedExtractors(extractor)\n",
    "\n",
    "# Test resume extraction\n",
    "print(\"\\n👤 Testing Resume Information Extraction:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "resume_info = specialized.extract_resume_info(resume_text)\n",
    "print(\"📄 Resume Extraction Results:\")\n",
    "print(json.dumps(resume_info, indent=2, ensure_ascii=False)[:1000] + \"...\")\n",
    "\n",
    "# Create sample academic paper for testing\n",
    "academic_paper_text = \"\"\"\n",
    "Deep Learning for Natural Language Processing: A Comprehensive Survey\n",
    "\n",
    "Abstract:\n",
    "This paper presents a comprehensive survey of deep learning techniques applied to natural language processing (NLP) tasks. We review the evolution from traditional machine learning approaches to modern transformer-based architectures, analyzing their strengths and limitations across various NLP applications.\n",
    "\n",
    "Authors:\n",
    "- Dr. Sarah Johnson, Stanford University, Computer Science Department\n",
    "- Prof. Michael Chen, MIT, Artificial Intelligence Lab\n",
    "- Dr. Elena Rodriguez, Google Research, NLP Team\n",
    "\n",
    "Keywords: deep learning, natural language processing, transformers, BERT, GPT, neural networks, language models\n",
    "\n",
    "1. Introduction\n",
    "Natural Language Processing has undergone significant transformation with the advent of deep learning techniques. Traditional approaches based on rule-based systems and statistical methods have largely been superseded by neural network architectures.\n",
    "\n",
    "2. Methodology\n",
    "We conducted a systematic literature review of 150+ papers published between 2018-2024, focusing on transformer architectures and their applications. Our analysis covers supervised, unsupervised, and semi-supervised learning paradigms.\n",
    "\n",
    "3. Key Findings\n",
    "- Transformer models achieve state-of-the-art performance across multiple NLP benchmarks\n",
    "- Pre-training on large corpora followed by fine-tuning shows consistent improvements\n",
    "- Attention mechanisms enable better handling of long-range dependencies\n",
    "- Model size correlates with performance up to a saturation point\n",
    "\n",
    "4. Applications\n",
    "The reviewed techniques show effectiveness in:\n",
    "- Machine Translation (BLEU scores improved by 15-20%)\n",
    "- Sentiment Analysis (accuracy gains of 10-12%)\n",
    "- Question Answering (F1 scores increased by 8-15%)\n",
    "- Text Summarization (ROUGE scores improved by 12-18%)\n",
    "\n",
    "5. Conclusion\n",
    "Deep learning has revolutionized NLP, with transformer architectures leading current advances. Future research should focus on efficiency improvements and multi-modal integration.\n",
    "\n",
    "References: [1-47 academic citations listed]\n",
    "\n",
    "Published in: Journal of Artificial Intelligence Research, Vol. 28, 2024, pp. 1-25\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n📚 Testing Academic Paper Information Extraction:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "academic_info = specialized.extract_academic_paper_info(academic_paper_text)\n",
    "print(\"📄 Academic Paper Extraction Results:\")\n",
    "print(json.dumps(academic_info, indent=2, ensure_ascii=False)[:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79383dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. Validation and Schema Compliance\n",
    "# 驗證與 Schema 符合性檢查\n",
    "\n",
    "from pydantic import ValidationError\n",
    "import jsonschema\n",
    "\n",
    "\n",
    "class ExtractionValidator:\n",
    "    \"\"\"Validate extraction results against predefined schemas\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.validation_results = []\n",
    "\n",
    "    def validate_against_schema(self, data: Dict, schema_class) -> Dict:\n",
    "        \"\"\"Validate extracted data against Pydantic schema\"\"\"\n",
    "        try:\n",
    "            # Attempt to create model instance\n",
    "            validated_model = schema_class(**data)\n",
    "            return {\n",
    "                \"is_valid\": True,\n",
    "                \"validated_data\": validated_model.dict(),\n",
    "                \"errors\": [],\n",
    "            }\n",
    "        except ValidationError as e:\n",
    "            return {\n",
    "                \"is_valid\": False,\n",
    "                \"validated_data\": None,\n",
    "                \"errors\": [\n",
    "                    {\"field\": err[\"loc\"], \"message\": err[\"msg\"]} for err in e.errors\n",
    "                ],\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"is_valid\": False,\n",
    "                \"validated_data\": None,\n",
    "                \"errors\": [{\"field\": \"general\", \"message\": str(e)}],\n",
    "            }\n",
    "\n",
    "    def clean_and_retry_validation(self, data: Dict, schema_class) -> Dict:\n",
    "        \"\"\"Attempt to clean data and retry validation\"\"\"\n",
    "        cleaned_data = data.copy()\n",
    "\n",
    "        # Common cleaning operations\n",
    "        for key, value in cleaned_data.items():\n",
    "            if isinstance(value, str):\n",
    "                # Clean strings\n",
    "                cleaned_data[key] = value.strip()\n",
    "            elif isinstance(value, list):\n",
    "                # Clean lists - remove None values\n",
    "                cleaned_data[key] = [item for item in value if item is not None]\n",
    "\n",
    "        # Set default values for required fields if missing\n",
    "        if hasattr(schema_class, \"__fields__\"):\n",
    "            for field_name, field_info in schema_class.__fields__.items():\n",
    "                if field_name not in cleaned_data:\n",
    "                    if (\n",
    "                        hasattr(field_info, \"default\")\n",
    "                        and field_info.default is not None\n",
    "                    ):\n",
    "                        cleaned_data[field_name] = field_info.default\n",
    "                    elif field_info.type_ == str:\n",
    "                        cleaned_data[field_name] = \"\"\n",
    "                    elif field_info.type_ == list:\n",
    "                        cleaned_data[field_name] = []\n",
    "                    elif field_info.type_ == float:\n",
    "                        cleaned_data[field_name] = 0.0\n",
    "\n",
    "        return self.validate_against_schema(cleaned_data, schema_class)\n",
    "\n",
    "\n",
    "# Test validation\n",
    "# 測試驗證功能\n",
    "validator = ExtractionValidator()\n",
    "\n",
    "print(\"\\n✅ Testing Schema Validation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Validate sample extraction result\n",
    "validation_result = validator.validate_against_schema(extracted_info, DocumentSummary)\n",
    "print(\n",
    "    f\"Validation Result: {'✅ VALID' if validation_result['is_valid'] else '❌ INVALID'}\"\n",
    ")\n",
    "\n",
    "if not validation_result[\"is_valid\"]:\n",
    "    print(\"Validation Errors:\")\n",
    "    for error in validation_result[\"errors\"]:\n",
    "        print(f\"  - {error['field']}: {error['message']}\")\n",
    "\n",
    "    # Try cleaning and re-validation\n",
    "    print(\"\\n🔧 Attempting to clean and re-validate...\")\n",
    "    cleaned_validation = validator.clean_and_retry_validation(\n",
    "        extracted_info, DocumentSummary\n",
    "    )\n",
    "    print(\n",
    "        f\"Cleaned Validation: {'✅ VALID' if cleaned_validation['is_valid'] else '❌ STILL INVALID'}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da0505",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9. Performance Monitoring and Optimization\n",
    "# 性能監控與優化\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    \"\"\"Monitor extraction performance and resource usage\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.metrics = []\n",
    "\n",
    "    def measure_extraction_performance(\n",
    "        self, extractor: LLMExtractor, text: str, schema_type: str = \"general\"\n",
    "    ) -> Dict:\n",
    "        \"\"\"Measure extraction performance metrics\"\"\"\n",
    "\n",
    "        # Clear GPU cache before measurement\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            initial_vram = torch.cuda.memory_allocated()\n",
    "\n",
    "        initial_ram = psutil.virtual_memory().used\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Perform extraction\n",
    "        try:\n",
    "            result = extractor.extract_structured_info(text, schema_type)\n",
    "            success = True\n",
    "            error = None\n",
    "        except Exception as e:\n",
    "            result = None\n",
    "            success = False\n",
    "            error = str(e)\n",
    "\n",
    "        end_time = time.time()\n",
    "        final_ram = psutil.virtual_memory().used\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            final_vram = torch.cuda.memory_allocated()\n",
    "            vram_used = (final_vram - initial_vram) / 1e6  # MB\n",
    "        else:\n",
    "            vram_used = 0\n",
    "\n",
    "        ram_used = (final_ram - initial_ram) / 1e6  # MB\n",
    "        processing_time = end_time - start_time\n",
    "\n",
    "        metrics = {\n",
    "            \"processing_time_seconds\": processing_time,\n",
    "            \"ram_used_mb\": ram_used,\n",
    "            \"vram_used_mb\": vram_used,\n",
    "            \"text_length\": len(text),\n",
    "            \"tokens_per_second\": (\n",
    "                len(text.split()) / processing_time if processing_time > 0 else 0\n",
    "            ),\n",
    "            \"success\": success,\n",
    "            \"error\": error,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "        self.metrics.append(metrics)\n",
    "        return metrics\n",
    "\n",
    "    def get_performance_summary(self) -> Dict:\n",
    "        \"\"\"Generate performance summary statistics\"\"\"\n",
    "        if not self.metrics:\n",
    "            return {\"message\": \"No performance data available\"}\n",
    "\n",
    "        successful_runs = [m for m in self.metrics if m[\"success\"]]\n",
    "\n",
    "        if not successful_runs:\n",
    "            return {\"message\": \"No successful runs to analyze\"}\n",
    "\n",
    "        processing_times = [m[\"processing_time_seconds\"] for m in successful_runs]\n",
    "        ram_usage = [m[\"ram_used_mb\"] for m in successful_runs]\n",
    "        vram_usage = [m[\"vram_used_mb\"] for m in successful_runs]\n",
    "\n",
    "        return {\n",
    "            \"total_runs\": len(self.metrics),\n",
    "            \"successful_runs\": len(successful_runs),\n",
    "            \"success_rate\": len(successful_runs) / len(self.metrics) * 100,\n",
    "            \"average_processing_time\": sum(processing_times) / len(processing_times),\n",
    "            \"min_processing_time\": min(processing_times),\n",
    "            \"max_processing_time\": max(processing_times),\n",
    "            \"average_ram_usage_mb\": sum(ram_usage) / len(ram_usage),\n",
    "            \"average_vram_usage_mb\": sum(vram_usage) / len(vram_usage),\n",
    "            \"average_tokens_per_second\": sum(\n",
    "                m[\"tokens_per_second\"] for m in successful_runs\n",
    "            )\n",
    "            / len(successful_runs),\n",
    "        }\n",
    "\n",
    "\n",
    "# Test performance monitoring\n",
    "# 測試性能監控\n",
    "monitor = PerformanceMonitor()\n",
    "\n",
    "print(\"\\n⚡ Performance Testing:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test with sample documents\n",
    "test_texts = [\n",
    "    sample_text,\n",
    "    contract_text,\n",
    "    resume_text[:1000],\n",
    "]  # Truncate for faster testing\n",
    "\n",
    "for i, text in enumerate(test_texts):\n",
    "    print(f\"\\nTesting document {i+1}...\")\n",
    "    perf_metrics = monitor.measure_extraction_performance(extractor, text)\n",
    "    print(f\"  Processing time: {perf_metrics['processing_time_seconds']:.2f}s\")\n",
    "    print(f\"  RAM used: {perf_metrics['ram_used_mb']:.1f}MB\")\n",
    "    print(f\"  VRAM used: {perf_metrics['vram_used_mb']:.1f}MB\")\n",
    "    print(f\"  Success: {'✅' if perf_metrics['success'] else '❌'}\")\n",
    "\n",
    "# Performance summary\n",
    "perf_summary = monitor.get_performance_summary()\n",
    "print(f\"\\n📊 Performance Summary:\")\n",
    "for key, value in perf_summary.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ad4218",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10. Smoke Test & Validation\n",
    "# 驗收測試與驗證\n",
    "\n",
    "\n",
    "def run_smoke_test():\n",
    "    \"\"\"Comprehensive smoke test for document extraction pipeline\"\"\"\n",
    "    print(\"\\n🧪 Running Comprehensive Smoke Test...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    test_results = {\n",
    "        \"parser_test\": False,\n",
    "        \"extractor_test\": False,\n",
    "        \"pipeline_test\": False,\n",
    "        \"validation_test\": False,\n",
    "        \"performance_test\": False,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Test 1: Document Parser\n",
    "        print(\"1️⃣ Testing Document Parser...\")\n",
    "        test_parser = DocumentParser()\n",
    "        test_doc = test_parser.parse(sample_path)\n",
    "        assert test_doc.text is not None\n",
    "        assert len(test_doc.text) > 0\n",
    "        test_results[\"parser_test\"] = True\n",
    "        print(\"   ✅ Parser works correctly\")\n",
    "\n",
    "        # Test 2: Information Extractor\n",
    "        print(\"2️⃣ Testing Information Extractor...\")\n",
    "        test_extractor = LLMExtractor()\n",
    "        test_extraction = test_extractor.extract_structured_info(sample_text[:500])\n",
    "        assert isinstance(test_extraction, dict)\n",
    "        assert \"document_type\" in test_extraction\n",
    "        test_results[\"extractor_test\"] = True\n",
    "        print(\"   ✅ Extractor works correctly\")\n",
    "\n",
    "        # Test 3: Processing Pipeline\n",
    "        print(\"3️⃣ Testing Processing Pipeline...\")\n",
    "        test_pipeline = DocumentProcessingPipeline(\n",
    "            test_parser, test_extractor, max_workers=1\n",
    "        )\n",
    "        pipeline_result = test_pipeline.process_single_document(sample_path)\n",
    "        assert pipeline_result[\"status\"] == \"success\"\n",
    "        assert \"extracted_info\" in pipeline_result\n",
    "        test_results[\"pipeline_test\"] = True\n",
    "        print(\"   ✅ Pipeline works correctly\")\n",
    "\n",
    "        # Test 4: Schema Validation\n",
    "        print(\"4️⃣ Testing Schema Validation...\")\n",
    "        test_validator = ExtractionValidator()\n",
    "        validation_result = test_validator.validate_against_schema(\n",
    "            test_extraction, DocumentSummary\n",
    "        )\n",
    "        # Should either be valid or cleanable\n",
    "        if not validation_result[\"is_valid\"]:\n",
    "            cleaned_result = test_validator.clean_and_retry_validation(\n",
    "                test_extraction, DocumentSummary\n",
    "            )\n",
    "            assert (\n",
    "                cleaned_result[\"is_valid\"] or len(cleaned_result[\"errors\"]) < 5\n",
    "            )  # Allow some errors\n",
    "        test_results[\"validation_test\"] = True\n",
    "        print(\"   ✅ Validation works correctly\")\n",
    "\n",
    "        # Test 5: Performance Monitoring\n",
    "        print(\"5️⃣ Testing Performance Monitoring...\")\n",
    "        test_monitor = PerformanceMonitor()\n",
    "        perf_result = test_monitor.measure_extraction_performance(\n",
    "            test_extractor, sample_text[:300]\n",
    "        )\n",
    "        assert \"processing_time_seconds\" in perf_result\n",
    "        assert perf_result[\"processing_time_seconds\"] > 0\n",
    "        test_results[\"performance_test\"] = True\n",
    "        print(\"   ✅ Performance monitoring works correctly\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "    # Final results\n",
    "    all_passed = all(test_results.values())\n",
    "    print(f\"\\n🎯 Smoke Test Results:\")\n",
    "    for test_name, passed in test_results.items():\n",
    "        status = \"✅ PASS\" if passed else \"❌ FAIL\"\n",
    "        print(f\"   {test_name}: {status}\")\n",
    "\n",
    "    print(f\"\\n{'🎉 ALL TESTS PASSED!' if all_passed else '⚠️ SOME TESTS FAILED'}\")\n",
    "    return all_passed\n",
    "\n",
    "\n",
    "# Run comprehensive smoke test\n",
    "smoke_test_result = run_smoke_test()\n",
    "\n",
    "# Cleanup test files\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.remove(sample_path)\n",
    "    os.remove(contract_path)\n",
    "    os.remove(resume_path)\n",
    "    os.remove(\"extraction_results.json\")\n",
    "    print(\"\\n🧹 Cleanup completed - test files removed\")\n",
    "except:\n",
    "    print(\"\\n⚠️ Some test files could not be removed\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"📋 NOTEBOOK COMPLETION SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(\n",
    "    \"\"\"\n",
    "✅ 完成項目 (Completed Items):\n",
    "  • 多格式文件解析器 (PDF/DOCX/HTML/TXT/MD)\n",
    "  • Pydantic Schema 定義與驗證\n",
    "  • LLM 結構化資訊抽取引擎\n",
    "  • 批量處理管線與錯誤處理\n",
    "  • 專門抽取器 (簡歷/合約/學術論文)\n",
    "  • 品質評估與準確率計算\n",
    "  • 性能監控與資源使用追蹤\n",
    "  • 完整的驗收測試流程\n",
    "\n",
    "🧠 核心概念 (Core Concepts):\n",
    "  • Schema-driven Extraction: 使用 Pydantic 定義結構化輸出格式\n",
    "  • Multi-format Parsing: 統一介面處理不同文件格式\n",
    "  • LLM Prompting for IE: 結構化提示工程進行資訊抽取\n",
    "  • Quality Assessment: 準確率、召回率、F1-score 評估\n",
    "  • Performance Optimization: 低 VRAM 配置與批量處理\n",
    "  • Error Handling: 容錯機制與降級策略\n",
    "\n",
    "⚠️ 常見問題 (Common Issues):\n",
    "  • 模型載入失敗 → 使用 4-bit 量化或降級至 CPU\n",
    "  • JSON 解析錯誤 → 實作正規表達式後備方案\n",
    "  • 記憶體不足 → 減少 batch size 或使用序列處理\n",
    "  • 抽取準確率低 → 調整提示詞或使用更大模型\n",
    "  • Schema 驗證失敗 → 實作資料清理與預設值\n",
    "\n",
    "🚀 下一步建議 (Next Steps):\n",
    "  1. 整合向量資料庫進行語意搜尋\n",
    "  2. 加入多語言支援 (中文/英文混合)\n",
    "  3. 實作增量學習機制改善抽取品質\n",
    "  4. 開發 Web UI 進行互動式文件分析\n",
    "  5. 整合 OCR 功能處理掃描文件\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63acd009",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11. Advanced Features & Extensions (Optional)\n",
    "# 進階功能與擴展 (可選)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"🔬 ADVANCED FEATURES PREVIEW\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(\n",
    "    \"\"\"\n",
    "💡 可選擴展功能 (Optional Extensions):\n",
    "\n",
    "1. 📸 OCR Integration (光學字符識別)\n",
    "   - 使用 pytesseract 或 EasyOCR 處理掃描文件\n",
    "   - 支援中英文混合識別\n",
    "   - 表格結構保持\n",
    "\n",
    "2. 🌐 Multilingual Support (多語言支援)\n",
    "   - 中文實體識別與關係抽取\n",
    "   - 繁簡轉換 (opencc)\n",
    "   - 跨語言 Schema 映射\n",
    "\n",
    "3. 🔄 Active Learning (主動學習)\n",
    "   - 標註介面整合\n",
    "   - 不確定性採樣\n",
    "   - 漸進式模型改善\n",
    "\n",
    "4. 📊 Dashboard & Analytics (儀表板分析)\n",
    "   - Streamlit/Gradio 網頁介面\n",
    "   - 即時抽取準確率監控\n",
    "   - 文件類型分布分析\n",
    "\n",
    "5. 🔗 API Integration (API 整合)\n",
    "   - RESTful API endpoints\n",
    "   - Webhook 支援批量處理\n",
    "   - 雲端儲存整合 (S3/GCS)\n",
    "\n",
    "6. 🎯 Domain Adaptation (領域適應)\n",
    "   - 醫療文件專用抽取器\n",
    "   - 法律合約風險評估\n",
    "   - 財務報表數據驗證\n",
    "\n",
    "使用指令查看具體實作:\n",
    "  • nb17_multilingual_ocr.ipynb\n",
    "  • nb18_active_learning_pipeline.ipynb\n",
    "  • nb19_document_analytics_dashboard.ipynb\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(f\"\\n🎓 學習建議 (Learning Recommendations):\")\n",
    "print(\n",
    "    \"\"\"\n",
    "1. 先熟練基本抽取管線，再嘗試進階功能\n",
    "2. 針對特定領域收集高品質標註資料\n",
    "3. 比較不同 LLM 在結構化抽取的表現\n",
    "4. 建立評估基準以量化改善效果\n",
    "5. 考慮成本效益平衡 (準確率 vs 處理速度)\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c880b18a",
   "metadata": {},
   "source": [
    "\n",
    "### 📋 本章小結\n",
    "\n",
    "**✅ 完成項目 (Completed Items):**\n",
    "- 多格式文件解析器 (PDF/DOCX/HTML/TXT/MD 統一介面)\n",
    "- Pydantic Schema 定義與驗證 (DocumentSummary, ContractInfo)\n",
    "- LLM 結構化資訊抽取引擎 (支援低 VRAM 配置)\n",
    "- 批量處理管線與錯誤處理 (並行處理與容錯機制)\n",
    "- 專門抽取器 (簡歷/合約/學術論文特化版本)\n",
    "- 品質評估模組 (準確率、召回率、F1-score)\n",
    "- 性能監控與資源使用追蹤 (RAM/VRAM 監控)\n",
    "- 完整的驗收測試流程 (端到端功能驗證)\n",
    "\n",
    "**🧠 核心原理 (Core Concepts):**\n",
    "- **Schema-driven Extraction**: 使用 Pydantic 定義結構化輸出格式，確保資料一致性\n",
    "- **Multi-format Parsing**: 統一介面處理不同文件格式，降低整合複雜度  \n",
    "- **LLM Prompting for IE**: 結構化提示工程進行資訊抽取，平衡準確率與可控性\n",
    "- **Quality Assessment**: 多維度評估指標 (欄位準確率、實體 F1、信心度相關性)\n",
    "- **Performance Optimization**: 低 VRAM 配置策略與批量處理最佳化\n",
    "\n",
    "**⚠️ 常見陷阱 (Common Pitfalls):**\n",
    "- 模型載入失敗 → 使用 4-bit 量化或降級至 CPU 模式\n",
    "- JSON 解析錯誤 → 實作正規表達式後備抽取方案  \n",
    "- 記憶體不足 → 減少 batch size 或改用序列處理\n",
    "- 抽取準確率低 → 調整提示詞模板或使用更大模型\n",
    "- Schema 驗證失敗 → 實作資料清理與預設值機制\n",
    "\n",
    "**🚀 下一步行動 (Next Actions):**\n",
    "1. **整合向量檢索**: 結合 `nb26_rag_basic_faiss.ipynb` 進行語意搜尋\n",
    "2. **多語言支援**: 加入中文實體識別與繁簡轉換\n",
    "3. **增量學習**: 實作主動學習機制持續改善抽取品質  \n",
    "4. **Web UI 開發**: 建立互動式文件分析介面\n",
    "5. **領域特化**: 針對醫療/法律/財務等特定領域客製化\n",
    "\n",
    "**💡 實務建議:**\n",
    "- 優先建立高品質的標註資料集作為評估基準\n",
    "- 比較不同 LLM (GPT/Qwen/DeepSeek) 在結構化抽取的表現差異\n",
    "- 考慮成本效益平衡：準確率提升 vs 處理速度與資源消耗\n",
    "- 建立監控儀表板追蹤生產環境的抽取品質變化\n",
    "\n",
    "這個 notebook 為後續的 RAG 應用和 Agent 系統提供了強大的文件理解基礎，是構建智能文件處理系統的重要里程碑。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
