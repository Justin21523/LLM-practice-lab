{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a89a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === nb14_react_multistep_reasoning.ipynb ===\n",
    "# ReAct å¤šæ­¥æ¨ç† (ReAct Multi-step Reasoning)\n",
    "# å­¸ç¿’ç›®æ¨™: æŒæ¡ Reasoning-Acting å¾ªç’°ã€å·¥å…·éˆæ•´åˆã€è¤‡é›œå•é¡Œåˆ†è§£\n",
    "\n",
    "# === Cell 1: Shared Cache Bootstrap ===\n",
    "import os, torch, platform, pathlib\n",
    "\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"/mnt/ai/cache\")\n",
    "paths = {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}\n",
    "for k, v in paths.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"[Cache] Root:\", AI_CACHE_ROOT)\n",
    "print(\n",
    "    \"[GPU]\",\n",
    "    torch.cuda.is_available(),\n",
    "    torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5500078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 2: Install Dependencies ===\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install package if not already installed\"\"\"\n",
    "    try:\n",
    "        __import__(package.split(\"[\")[0])\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "\n",
    "# Install required packages\n",
    "packages = [\n",
    "    \"transformers>=4.36.0\",\n",
    "    \"accelerate\",\n",
    "    \"bitsandbytes\",\n",
    "    \"duckduckgo-search\",\n",
    "    \"beautifulsoup4\",\n",
    "    \"requests\",\n",
    "]\n",
    "\n",
    "for pkg in packages:\n",
    "    install_package(pkg)\n",
    "\n",
    "print(\"âœ… Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42786eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: ReAct æ ¸å¿ƒæ¦‚å¿µèªªæ˜ ===\n",
    "\"\"\"\n",
    "## ğŸ§  ReAct æ¨ç†æ¨¡å¼ (Reasoning and Acting)\n",
    "\n",
    "ReAct æ˜¯ä¸€ç¨®çµåˆæ¨ç† (Reasoning) èˆ‡è¡Œå‹• (Acting) çš„ AI æ™ºèƒ½é«”æ¨¡å¼ï¼š\n",
    "\n",
    "### æ ¸å¿ƒæ¦‚å¿µ (Core Concepts)\n",
    "- **Thought (æ€è€ƒ)**ï¼šAI åˆ†æç•¶å‰ç‹€æ³ï¼Œåˆ¶å®šä¸‹ä¸€æ­¥è¨ˆç•«\n",
    "- **Action (è¡Œå‹•)**ï¼šåŸ·è¡Œå…·é«”å·¥å…·èª¿ç”¨ (æœå°‹ã€è¨ˆç®—ã€æª¢ç´¢ç­‰)\n",
    "- **Observation (è§€å¯Ÿ)**ï¼šç²å–è¡Œå‹•çµæœï¼Œæ›´æ–°çŸ¥è­˜ç‹€æ…‹\n",
    "- **Reasoning Chain (æ¨ç†éˆ)**ï¼šæŒçºŒå¾ªç’°ç›´åˆ°å•é¡Œè§£æ±º\n",
    "\n",
    "### èˆ‡å…¶ä»–æ¨¡å¼æ¯”è¼ƒ\n",
    "- **Chain-of-Thought (CoT)**ï¼šç´”æ€ç¶­æ¨ç†ï¼Œç¼ºä¹å¤–éƒ¨å·¥å…·\n",
    "- **Direct Generation**ï¼šç›´æ¥ç”Ÿæˆç­”æ¡ˆï¼Œç„¡æ¨ç†éç¨‹\n",
    "- **ReAct**ï¼šæ€ç¶­ + å·¥å…·èª¿ç”¨ï¼Œé©åˆè¤‡é›œå¤šæ­¥å•é¡Œ\n",
    "\n",
    "### é©ç”¨å ´æ™¯\n",
    "âœ… éœ€è¦å¤–éƒ¨è³‡è¨Šçš„å•é¡Œ (æœå°‹ã€è¨ˆç®—)\n",
    "âœ… å¤šæ­¥é©Ÿåˆ†è§£çš„è¤‡é›œä»»å‹™\n",
    "âœ… éœ€è¦é©—è­‰èˆ‡ä¿®æ­£çš„æ¨ç†éç¨‹\n",
    "âŒ ç´”å‰µæ„å¯«ä½œæˆ–ç°¡å–®å•ç­”\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a71719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 4: Basic Tools Definition ===\n",
    "import requests\n",
    "from typing import Dict, Any, List, Optional\n",
    "import json\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class SearchTool:\n",
    "    \"\"\"Web search tool using DuckDuckGo (no API key required)\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"search\"\n",
    "        self.description = \"Search the web for current information\"\n",
    "\n",
    "    def execute(self, query: str) -> str:\n",
    "        \"\"\"Execute web search and return results\"\"\"\n",
    "        try:\n",
    "            from duckduckgo_search import DDGS\n",
    "\n",
    "            with DDGS() as ddgs:\n",
    "                results = list(ddgs.text(query, max_results=3))\n",
    "\n",
    "            if not results:\n",
    "                return \"No search results found\"\n",
    "\n",
    "            formatted_results = []\n",
    "            for i, result in enumerate(results, 1):\n",
    "                formatted_results.append(\n",
    "                    f\"{i}. {result['title']}\\n\"\n",
    "                    f\"   {result['body'][:200]}...\\n\"\n",
    "                    f\"   Source: {result['href']}\\n\"\n",
    "                )\n",
    "\n",
    "            return \"\\n\".join(formatted_results)\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Search error: {str(e)}\"\n",
    "\n",
    "\n",
    "class CalculatorTool:\n",
    "    \"\"\"Mathematical calculation tool\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"calculator\"\n",
    "        self.description = \"Perform mathematical calculations\"\n",
    "\n",
    "    def execute(self, expression: str) -> str:\n",
    "        \"\"\"Execute mathematical calculation\"\"\"\n",
    "        try:\n",
    "            # Clean and validate expression\n",
    "            cleaned = re.sub(r\"[^0-9+\\-*/.() ]\", \"\", expression)\n",
    "\n",
    "            # Safe evaluation\n",
    "            result = eval(cleaned)\n",
    "            return f\"Calculation: {expression} = {result}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Calculation error: {str(e)}\"\n",
    "\n",
    "\n",
    "class MemoryTool:\n",
    "    \"\"\"Simple memory storage for conversation context\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"memory\"\n",
    "        self.description = \"Store and retrieve information\"\n",
    "        self.storage = {}\n",
    "\n",
    "    def execute(self, action: str, key: str = None, value: str = None) -> str:\n",
    "        \"\"\"Execute memory operations (store/retrieve)\"\"\"\n",
    "        try:\n",
    "            if action == \"store\" and key and value:\n",
    "                self.storage[key] = value\n",
    "                return f\"Stored: {key} = {value}\"\n",
    "\n",
    "            elif action == \"retrieve\" and key:\n",
    "                if key in self.storage:\n",
    "                    return f\"Retrieved: {key} = {self.storage[key]}\"\n",
    "                else:\n",
    "                    return f\"Key '{key}' not found in memory\"\n",
    "\n",
    "            elif action == \"list\":\n",
    "                if self.storage:\n",
    "                    items = [f\"{k}: {v}\" for k, v in self.storage.items()]\n",
    "                    return \"Memory contents:\\n\" + \"\\n\".join(items)\n",
    "                else:\n",
    "                    return \"Memory is empty\"\n",
    "\n",
    "            else:\n",
    "                return \"Invalid memory operation. Use: store/retrieve/list\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Memory error: {str(e)}\"\n",
    "\n",
    "\n",
    "# Initialize tools\n",
    "search_tool = SearchTool()\n",
    "calc_tool = CalculatorTool()\n",
    "memory_tool = MemoryTool()\n",
    "\n",
    "print(\"ğŸ› ï¸ Tools initialized:\")\n",
    "print(f\"- {search_tool.name}: {search_tool.description}\")\n",
    "print(f\"- {calc_tool.name}: {calc_tool.description}\")\n",
    "print(f\"- {memory_tool.name}: {memory_tool.description}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 5: LLM Adapter (Lightweight) ===\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "\n",
    "class SimpleLLMAdapter:\n",
    "    \"\"\"Lightweight LLM adapter for ReAct reasoning\"\"\"\n",
    "\n",
    "    def __init__(self, model_id: str = \"microsoft/DialoGPT-medium\"):\n",
    "        self.model_id = model_id\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        print(f\"Loading model: {model_id}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            load_in_4bit=torch.cuda.is_available(),  # Use 4bit if GPU available\n",
    "        )\n",
    "\n",
    "        # Add padding token if missing\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def generate(self, prompt: str, max_tokens: int = 256) -> str:\n",
    "        \"\"\"Generate response from prompt\"\"\"\n",
    "        try:\n",
    "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    inputs,\n",
    "                    max_new_tokens=max_tokens,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.7,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id,\n",
    "                    attention_mask=torch.ones_like(inputs),\n",
    "                )\n",
    "\n",
    "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "            # Extract only the new generation\n",
    "            if prompt in response:\n",
    "                response = response.replace(prompt, \"\").strip()\n",
    "\n",
    "            return response\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Generation error: {str(e)}\"\n",
    "\n",
    "\n",
    "# For demo purposes, we'll use a simple mock LLM\n",
    "class MockLLM:\n",
    "    \"\"\"Mock LLM for demonstration (replace with real LLM in production)\"\"\"\n",
    "\n",
    "    def generate(self, prompt: str, max_tokens: int = 256) -> str:\n",
    "        \"\"\"Generate mock responses based on prompt patterns\"\"\"\n",
    "        prompt_lower = prompt.lower()\n",
    "\n",
    "        if \"thought:\" in prompt_lower and \"search\" in prompt_lower:\n",
    "            return \"I need to search for current information about this topic.\"\n",
    "        elif \"thought:\" in prompt_lower and \"calculate\" in prompt_lower:\n",
    "            return \"I need to perform some mathematical calculations.\"\n",
    "        elif \"action:\" in prompt_lower:\n",
    "            return \"Executing the planned action...\"\n",
    "        else:\n",
    "            return \"Let me think about this step by step.\"\n",
    "\n",
    "\n",
    "# Use MockLLM for demo (replace with real LLM)\n",
    "llm = MockLLM()\n",
    "print(\"ğŸ¤– LLM adapter initialized (using mock for demo)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651d4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 6: ReAct Agent Core Implementation ===\n",
    "import re\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "\n",
    "class ReActAgent:\n",
    "    \"\"\"ReAct (Reasoning + Acting) Agent implementation\"\"\"\n",
    "\n",
    "    def __init__(self, llm, tools: Dict[str, Any], max_iterations: int = 5):\n",
    "        self.llm = llm\n",
    "        self.tools = tools\n",
    "        self.max_iterations = max_iterations\n",
    "        self.reasoning_chain = []\n",
    "\n",
    "    def parse_action(self, text: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "        \"\"\"Parse action from LLM response\"\"\"\n",
    "        # Look for Action[tool_name]: query pattern\n",
    "        action_pattern = r\"Action\\[([^\\]]+)\\]:\\s*(.+)\"\n",
    "        match = re.search(action_pattern, text, re.IGNORECASE)\n",
    "\n",
    "        if match:\n",
    "            tool_name = match.group(1).strip()\n",
    "            query = match.group(2).strip()\n",
    "            return tool_name, query\n",
    "\n",
    "        return None, None\n",
    "\n",
    "    def execute_tool(self, tool_name: str, query: str) -> str:\n",
    "        \"\"\"Execute tool with given query\"\"\"\n",
    "        if tool_name not in self.tools:\n",
    "            return f\"Error: Tool '{tool_name}' not found. Available tools: {list(self.tools.keys())}\"\n",
    "\n",
    "        tool = self.tools[tool_name]\n",
    "\n",
    "        try:\n",
    "            if tool_name == \"memory\":\n",
    "                # Parse memory operations\n",
    "                parts = query.split(\",\")\n",
    "                if len(parts) >= 2:\n",
    "                    action = parts[0].strip()\n",
    "                    key = parts[1].strip() if len(parts) > 1 else None\n",
    "                    value = parts[2].strip() if len(parts) > 2 else None\n",
    "                    return tool.execute(action, key, value)\n",
    "                else:\n",
    "                    return tool.execute(query)\n",
    "            else:\n",
    "                return tool.execute(query)\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Tool execution error: {str(e)}\"\n",
    "\n",
    "    def solve(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"Solve question using ReAct reasoning\"\"\"\n",
    "        self.reasoning_chain = []\n",
    "\n",
    "        # Initial prompt setup\n",
    "        system_prompt = \"\"\"You are an AI assistant that uses ReAct (Reasoning + Acting) to solve problems.\n",
    "\n",
    "Available tools:\n",
    "- search: Search the web for information\n",
    "- calculator: Perform mathematical calculations\n",
    "- memory: Store and retrieve information (actions: store,key,value or retrieve,key or list)\n",
    "\n",
    "Format your responses as:\n",
    "Thought: [Your reasoning about what to do next]\n",
    "Action[tool_name]: query\n",
    "Observation: [Tool result will be provided]\n",
    "\n",
    "Continue this cycle until you can provide a Final Answer.\n",
    "\n",
    "Example:\n",
    "Thought: I need to search for information about this topic.\n",
    "Action[search]: what is the capital of France\n",
    "Observation: [Search results will appear here]\n",
    "Thought: Based on the search results, I can now answer.\n",
    "Final Answer: The capital of France is Paris.\n",
    "\"\"\"\n",
    "\n",
    "        current_prompt = f\"{system_prompt}\\n\\nQuestion: {question}\\n\\n\"\n",
    "\n",
    "        for iteration in range(self.max_iterations):\n",
    "            print(f\"\\n=== Iteration {iteration + 1} ===\")\n",
    "\n",
    "            # Generate reasoning\n",
    "            response = self.llm.generate(current_prompt, max_tokens=256)\n",
    "            print(f\"Response: {response}\")\n",
    "\n",
    "            # Record step\n",
    "            step = {\n",
    "                \"iteration\": iteration + 1,\n",
    "                \"prompt\": current_prompt,\n",
    "                \"response\": response,\n",
    "                \"action\": None,\n",
    "                \"observation\": None,\n",
    "            }\n",
    "\n",
    "            # Check for final answer\n",
    "            if \"final answer:\" in response.lower():\n",
    "                step[\"final_answer\"] = True\n",
    "                self.reasoning_chain.append(step)\n",
    "\n",
    "                # Extract final answer\n",
    "                final_answer_match = re.search(\n",
    "                    r\"final answer:\\s*(.+)\", response, re.IGNORECASE\n",
    "                )\n",
    "                final_answer = (\n",
    "                    final_answer_match.group(1) if final_answer_match else response\n",
    "                )\n",
    "\n",
    "                return {\n",
    "                    \"success\": True,\n",
    "                    \"answer\": final_answer,\n",
    "                    \"reasoning_chain\": self.reasoning_chain,\n",
    "                    \"iterations\": iteration + 1,\n",
    "                }\n",
    "\n",
    "            # Parse and execute action\n",
    "            tool_name, query = self.parse_action(response)\n",
    "\n",
    "            if tool_name and query:\n",
    "                print(f\"Executing: {tool_name}({query})\")\n",
    "\n",
    "                observation = self.execute_tool(tool_name, query)\n",
    "                print(f\"Observation: {observation}\")\n",
    "\n",
    "                step[\"action\"] = {\"tool\": tool_name, \"query\": query}\n",
    "                step[\"observation\"] = observation\n",
    "\n",
    "                # Update prompt with observation\n",
    "                current_prompt += f\"{response}\\nObservation: {observation}\\n\\n\"\n",
    "\n",
    "            else:\n",
    "                # No action found, continue with reasoning\n",
    "                current_prompt += f\"{response}\\n\\n\"\n",
    "\n",
    "            self.reasoning_chain.append(step)\n",
    "\n",
    "        # Max iterations reached\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"answer\": \"Maximum iterations reached without finding answer\",\n",
    "            \"reasoning_chain\": self.reasoning_chain,\n",
    "            \"iterations\": self.max_iterations,\n",
    "        }\n",
    "\n",
    "\n",
    "# Initialize ReAct agent\n",
    "tools_dict = {\"search\": search_tool, \"calculator\": calc_tool, \"memory\": memory_tool}\n",
    "\n",
    "react_agent = ReActAgent(llm, tools_dict, max_iterations=5)\n",
    "print(\"ğŸ§  ReAct Agent initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904fa364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 7: Simple Reasoning Example ===\n",
    "print(\"=== ç°¡å–®æ¨ç†ç¯„ä¾‹ (Simple Reasoning Example) ===\")\n",
    "\n",
    "# Example 1: Direct calculation\n",
    "simple_question = \"What is 15% of 2,500?\"\n",
    "\n",
    "print(f\"Question: {simple_question}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Manual ReAct simulation for demo\n",
    "print(\"Thought: I need to calculate 15% of 2,500\")\n",
    "print(\"Action[calculator]: 2500 * 0.15\")\n",
    "\n",
    "calc_result = calc_tool.execute(\"2500 * 0.15\")\n",
    "print(f\"Observation: {calc_result}\")\n",
    "\n",
    "print(\"Thought: The calculation is complete\")\n",
    "print(\"Final Answer: 15% of 2,500 is 375\")\n",
    "\n",
    "print(\"\\nâœ… Simple reasoning completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03462cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 8: Multi-step Reasoning Example ===\n",
    "print(\"=== å¤šæ­¥æ¨ç†ç¯„ä¾‹ (Multi-step Reasoning Example) ===\")\n",
    "\n",
    "# Complex question requiring multiple steps\n",
    "complex_question = \"If I invest $10,000 at 3% annual interest compounded annually, how much will I have after 5 years?\"\n",
    "\n",
    "print(f\"Question: {complex_question}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Step 1: Store initial values\n",
    "print(\n",
    "    \"Thought: I need to solve a compound interest problem. Let me store the given values first.\"\n",
    ")\n",
    "print(\"Action[memory]: store,principal,10000\")\n",
    "memory_result1 = memory_tool.execute(\"store\", \"principal\", \"10000\")\n",
    "print(f\"Observation: {memory_result1}\")\n",
    "\n",
    "print(\"Action[memory]: store,rate,0.03\")\n",
    "memory_result2 = memory_tool.execute(\"store\", \"rate\", \"0.03\")\n",
    "print(f\"Observation: {memory_result2}\")\n",
    "\n",
    "print(\"Action[memory]: store,time,5\")\n",
    "memory_result3 = memory_tool.execute(\"store\", \"time\", \"5\")\n",
    "print(f\"Observation: {memory_result3}\")\n",
    "\n",
    "# Step 2: Apply compound interest formula\n",
    "print(\n",
    "    \"\\nThought: Now I'll calculate using the compound interest formula: A = P(1 + r)^t\"\n",
    ")\n",
    "print(\"Action[calculator]: 10000 * (1.03 ** 5)\")\n",
    "compound_result = calc_tool.execute(\"10000 * (1.03 ** 5)\")\n",
    "print(f\"Observation: {compound_result}\")\n",
    "\n",
    "# Step 3: Calculate interest earned\n",
    "print(\"\\nThought: Let me also calculate the interest earned\")\n",
    "print(\"Action[calculator]: 11592.74 - 10000\")\n",
    "interest_result = calc_tool.execute(\"11592.74 - 10000\")\n",
    "print(f\"Observation: {interest_result}\")\n",
    "\n",
    "print(\"\\nThought: I have all the information needed to provide a complete answer\")\n",
    "print(\n",
    "    \"Final Answer: After 5 years, your $10,000 investment at 3% annual compound interest will grow to approximately $11,592.74, earning $1,592.74 in interest.\"\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Multi-step reasoning completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b1a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 9: Reasoning Chain Visualization ===\n",
    "def visualize_reasoning_chain(steps: List[Dict], title: str = \"Reasoning Chain\"):\n",
    "    \"\"\"Visualize the reasoning process\"\"\"\n",
    "    print(f\"\\nğŸ“Š {title}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for i, step in enumerate(steps, 1):\n",
    "        print(f\"\\nğŸ”¹ Step {i}:\")\n",
    "\n",
    "        if \"thought\" in step:\n",
    "            print(f\"   ğŸ’­ Thought: {step['thought']}\")\n",
    "\n",
    "        if \"action\" in step and step[\"action\"]:\n",
    "            action = step[\"action\"]\n",
    "            print(f\"   ğŸ”§ Action: {action['tool']}({action['query']})\")\n",
    "\n",
    "        if \"observation\" in step and step[\"observation\"]:\n",
    "            obs = (\n",
    "                step[\"observation\"][:100] + \"...\"\n",
    "                if len(step[\"observation\"]) > 100\n",
    "                else step[\"observation\"]\n",
    "            )\n",
    "            print(f\"   ğŸ‘€ Observation: {obs}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "# Simulate a reasoning chain for visualization\n",
    "demo_chain = [\n",
    "    {\n",
    "        \"thought\": \"I need to find current information about this topic\",\n",
    "        \"action\": {\"tool\": \"search\", \"query\": \"latest developments in AI\"},\n",
    "        \"observation\": \"Found 3 recent articles about AI developments...\",\n",
    "    },\n",
    "    {\n",
    "        \"thought\": \"Now I need to calculate some values based on the information\",\n",
    "        \"action\": {\"tool\": \"calculator\", \"query\": \"1000 * 1.05\"},\n",
    "        \"observation\": \"Calculation: 1000 * 1.05 = 1050.0\",\n",
    "    },\n",
    "    {\n",
    "        \"thought\": \"Let me store this result for later reference\",\n",
    "        \"action\": {\"tool\": \"memory\", \"query\": \"store,result,1050\"},\n",
    "        \"observation\": \"Stored: result = 1050\",\n",
    "    },\n",
    "]\n",
    "\n",
    "visualize_reasoning_chain(demo_chain, \"ç¤ºä¾‹æ¨ç†éˆ (Example Reasoning Chain)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a203377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 10: Error Handling and Recovery ===\n",
    "print(\"=== éŒ¯èª¤è™•ç†èˆ‡æ¢å¾©æ©Ÿåˆ¶ (Error Handling & Recovery) ===\")\n",
    "\n",
    "\n",
    "class RobustReActAgent(ReActAgent):\n",
    "    \"\"\"Enhanced ReAct agent with error handling\"\"\"\n",
    "\n",
    "    def __init__(self, llm, tools: Dict[str, Any], max_iterations: int = 5):\n",
    "        super().__init__(llm, tools, max_iterations)\n",
    "        self.error_count = 0\n",
    "        self.max_errors = 3\n",
    "\n",
    "    def handle_error(self, error_msg: str, step: int) -> str:\n",
    "        \"\"\"Handle errors and suggest recovery actions\"\"\"\n",
    "        self.error_count += 1\n",
    "\n",
    "        recovery_strategies = [\n",
    "            \"Let me try a different approach to this problem.\",\n",
    "            \"I'll reformulate my query and try again.\",\n",
    "            \"Let me break this down into smaller steps.\",\n",
    "        ]\n",
    "\n",
    "        if self.error_count <= self.max_errors:\n",
    "            strategy = recovery_strategies[\n",
    "                (self.error_count - 1) % len(recovery_strategies)\n",
    "            ]\n",
    "            return f\"Error encountered: {error_msg}\\nRecovery: {strategy}\"\n",
    "        else:\n",
    "            return f\"Too many errors ({self.error_count}). Unable to continue.\"\n",
    "\n",
    "    def execute_tool_safe(self, tool_name: str, query: str) -> str:\n",
    "        \"\"\"Execute tool with error handling\"\"\"\n",
    "        try:\n",
    "            result = self.execute_tool(tool_name, query)\n",
    "\n",
    "            # Check for error indicators\n",
    "            if \"error\" in result.lower():\n",
    "                return self.handle_error(result, len(self.reasoning_chain))\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            return self.handle_error(str(e), len(self.reasoning_chain))\n",
    "\n",
    "\n",
    "# Demonstrate error handling\n",
    "robust_agent = RobustReActAgent(llm, tools_dict)\n",
    "\n",
    "print(\"Testing error handling:\")\n",
    "print(\"1. Invalid tool name\")\n",
    "error_result = robust_agent.execute_tool_safe(\"invalid_tool\", \"test query\")\n",
    "print(f\"   Result: {error_result}\")\n",
    "\n",
    "print(\"\\n2. Invalid calculation\")\n",
    "error_result2 = robust_agent.execute_tool_safe(\"calculator\", \"invalid_expression!!!\")\n",
    "print(f\"   Result: {error_result2}\")\n",
    "\n",
    "print(\"\\nâœ… Error handling demonstrated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e69a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 11: Comparison of Reasoning Strategies ===\n",
    "def compare_reasoning_strategies():\n",
    "    \"\"\"Compare different reasoning approaches\"\"\"\n",
    "\n",
    "    question = \"What's the population of Tokyo and how does it compare to New York?\"\n",
    "\n",
    "    print(\"=== æ¨ç†ç­–ç•¥æ¯”è¼ƒ (Reasoning Strategy Comparison) ===\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    # 1. Direct Generation\n",
    "    print(\"\\nğŸ¯ Direct Generation:\")\n",
    "    print(\n",
    "        \"   Response: Tokyo has about 14 million people, while New York has about 8.3 million.\"\n",
    "    )\n",
    "    print(\"   Pros: Fast, simple\")\n",
    "    print(\"   Cons: May be outdated, no verification\")\n",
    "\n",
    "    # 2. Chain-of-Thought\n",
    "    print(\"\\nğŸ”— Chain-of-Thought:\")\n",
    "    print(\"   Thought: I need to consider both cities' populations...\")\n",
    "    print(\"   Thought: Tokyo is the capital of Japan, a major metropolitan area...\")\n",
    "    print(\"   Thought: New York is the largest city in the US...\")\n",
    "    print(\"   Response: Based on my knowledge, Tokyo has more people than New York.\")\n",
    "    print(\"   Pros: Shows reasoning process\")\n",
    "    print(\"   Cons: Still no external verification\")\n",
    "\n",
    "    # 3. ReAct\n",
    "    print(\"\\nğŸ§  ReAct:\")\n",
    "    print(\"   Thought: I need current population data for both cities\")\n",
    "    print(\"   Action[search]: Tokyo population 2024\")\n",
    "    print(\"   Observation: [Current search results]\")\n",
    "    print(\"   Thought: Now I need New York population data\")\n",
    "    print(\"   Action[search]: New York population 2024\")\n",
    "    print(\"   Observation: [Current search results]\")\n",
    "    print(\"   Thought: Let me calculate the difference\")\n",
    "    print(\"   Action[calculator]: tokyo_pop - ny_pop\")\n",
    "    print(\"   Final Answer: [Answer with current, verified data]\")\n",
    "    print(\"   Pros: Current data, verifiable, transparent process\")\n",
    "    print(\"   Cons: Slower, requires tools\")\n",
    "\n",
    "    return {\n",
    "        \"direct\": {\"speed\": \"fast\", \"accuracy\": \"medium\", \"transparency\": \"low\"},\n",
    "        \"cot\": {\"speed\": \"medium\", \"accuracy\": \"medium\", \"transparency\": \"high\"},\n",
    "        \"react\": {\"speed\": \"slow\", \"accuracy\": \"high\", \"transparency\": \"high\"},\n",
    "    }\n",
    "\n",
    "\n",
    "strategy_comparison = compare_reasoning_strategies()\n",
    "print(f\"\\nğŸ“Š Strategy Analysis: {strategy_comparison}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a8003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 12: Smoke Test ===\n",
    "def smoke_test_react():\n",
    "    \"\"\"Quick smoke test for ReAct functionality\"\"\"\n",
    "    print(\"ğŸ§ª ReAct Smoke Test\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Test 1: Tool availability\n",
    "    required_tools = [\"search\", \"calculator\", \"memory\"]\n",
    "    available_tools = list(tools_dict.keys())\n",
    "\n",
    "    print(\"1. Tool Availability:\")\n",
    "    for tool in required_tools:\n",
    "        status = \"âœ…\" if tool in available_tools else \"âŒ\"\n",
    "        print(f\"   {status} {tool}\")\n",
    "\n",
    "    # Test 2: Basic tool execution\n",
    "    print(\"\\n2. Tool Execution:\")\n",
    "\n",
    "    # Calculator test\n",
    "    calc_test = calc_tool.execute(\"2 + 2\")\n",
    "    calc_status = \"âœ…\" if \"4\" in calc_test else \"âŒ\"\n",
    "    print(f\"   {calc_status} Calculator: {calc_test}\")\n",
    "\n",
    "    # Memory test\n",
    "    memory_tool.execute(\"store\", \"test_key\", \"test_value\")\n",
    "    memory_test = memory_tool.execute(\"retrieve\", \"test_key\")\n",
    "    memory_status = \"âœ…\" if \"test_value\" in memory_test else \"âŒ\"\n",
    "    print(f\"   {memory_status} Memory: {memory_test}\")\n",
    "\n",
    "    # Test 3: Action parsing\n",
    "    print(\"\\n3. Action Parsing:\")\n",
    "    test_response = \"Action[calculator]: 10 + 5\"\n",
    "    tool_name, query = react_agent.parse_action(test_response)\n",
    "    parse_status = \"âœ…\" if tool_name == \"calculator\" and query == \"10 + 5\" else \"âŒ\"\n",
    "    print(f\"   {parse_status} Parse: {tool_name}, {query}\")\n",
    "\n",
    "    # Test 4: LLM basic generation\n",
    "    print(\"\\n4. LLM Generation:\")\n",
    "    llm_test = llm.generate(\"Test prompt\")\n",
    "    llm_status = \"âœ…\" if llm_test and len(llm_test) > 0 else \"âŒ\"\n",
    "    print(f\"   {llm_status} LLM: Generated {len(llm_test)} characters\")\n",
    "\n",
    "    print(\"\\nâœ… Smoke test completed\")\n",
    "\n",
    "\n",
    "smoke_test_react()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a9217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 13: Usage Examples and Best Practices ===\n",
    "print(\"=== ä½¿ç”¨ç¯„ä¾‹èˆ‡æœ€ä½³å¯¦è¸ (Usage Examples & Best Practices) ===\")\n",
    "\n",
    "usage_guide = \"\"\"\n",
    "## ğŸ¯ ReAct é©ç”¨å ´æ™¯ (When to Use ReAct)\n",
    "\n",
    "âœ… **é©åˆä½¿ç”¨ ReAct**:\n",
    "â€¢ éœ€è¦æœ€æ–°è³‡è¨Šçš„å•é¡Œ (è‚¡åƒ¹ã€æ–°èã€å¤©æ°£)\n",
    "â€¢ å¤šæ­¥è¨ˆç®—æˆ–åˆ†æä»»å‹™\n",
    "â€¢ éœ€è¦é©—è­‰äº‹å¯¦çš„æŸ¥è©¢\n",
    "â€¢ è¤‡é›œå•é¡Œåˆ†è§£ (ç ”ç©¶å ±å‘Šã€æ¯”è¼ƒåˆ†æ)\n",
    "â€¢ éœ€è¦å·¥å…·è¼”åŠ©çš„ä»»å‹™ (æª”æ¡ˆæ“ä½œã€API èª¿ç”¨)\n",
    "\n",
    "âŒ **ä¸é©åˆä½¿ç”¨ ReAct**:\n",
    "â€¢ ç°¡å–®å‰µæ„å¯«ä½œ\n",
    "â€¢ ç´”é‚è¼¯æ¨ç†å•é¡Œ (æ•¸å­¸è­‰æ˜)\n",
    "â€¢ å³æ™‚å°è©± (å»¶é²æ•æ„Ÿ)\n",
    "â€¢ å·²çŸ¥ç­”æ¡ˆçš„åŸºç¤å•é¡Œ\n",
    "\n",
    "## ğŸ› ï¸ å·¥å…·è¨­è¨ˆåŸå‰‡ (Tool Design Principles)\n",
    "\n",
    "1. **å–®ä¸€è·è²¬**: æ¯å€‹å·¥å…·å°ˆæ³¨ä¸€å€‹åŠŸèƒ½\n",
    "2. **éŒ¯èª¤è™•ç†**: å„ªé›…è™•ç†ç•°å¸¸æƒ…æ³\n",
    "3. **æ˜ç¢ºè¼¸å‡º**: çµæ§‹åŒ–ã€å¯è§£æçš„çµæœ\n",
    "4. **ç‹€æ…‹ç„¡é—œ**: å·¥å…·èª¿ç”¨æ‡‰è©²æ˜¯ç„¡ç‹€æ…‹çš„\n",
    "5. **å¿«é€ŸéŸ¿æ‡‰**: é¿å…é•·æ™‚é–“é˜»å¡æ“ä½œ\n",
    "\n",
    "## âš¡ æ€§èƒ½å„ªåŒ–å»ºè­° (Performance Tips)\n",
    "\n",
    "â€¢ **é™åˆ¶è¿­ä»£æ¬¡æ•¸**: é˜²æ­¢ç„¡é™å¾ªç’°\n",
    "â€¢ **å¿«å–çµæœ**: é¿å…é‡è¤‡å·¥å…·èª¿ç”¨\n",
    "â€¢ **ä¸¦è¡ŒåŸ·è¡Œ**: ç¨ç«‹å·¥å…·å¯ä¸¦è¡Œèª¿ç”¨\n",
    "â€¢ **æå‰çµ‚æ­¢**: æª¢æ¸¬åˆ°ç­”æ¡ˆæ™‚ç«‹å³åœæ­¢\n",
    "â€¢ **è¼•é‡ç´š LLM**: ä½¿ç”¨é©åˆä»»å‹™å¤§å°çš„æ¨¡å‹\n",
    "\n",
    "## ğŸ› å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ (Common Issues)\n",
    "\n",
    "1. **ç„¡é™å¾ªç’°**: è¨­ç½®æœ€å¤§è¿­ä»£æ¬¡æ•¸ï¼Œæª¢æ¸¬é‡è¤‡æ¨¡å¼\n",
    "2. **å·¥å…·èª¿ç”¨å¤±æ•—**: å¯¦ä½œé‡è©¦æ©Ÿåˆ¶å’Œé™ç´šç­–ç•¥\n",
    "3. **è§£æéŒ¯èª¤**: ä½¿ç”¨æ›´åš´æ ¼çš„æ ¼å¼æª¢æŸ¥\n",
    "4. **è¨˜æ†¶é«”æ´©æ¼**: å®šæœŸæ¸…ç†æ¨ç†éˆå’Œå·¥å…·ç‹€æ…‹\n",
    "5. **å›æ‡‰æ ¼å¼ä¸ä¸€è‡´**: ä½¿ç”¨çµæ§‹åŒ–æç¤ºå’Œæ ¼å¼é©—è­‰\n",
    "\"\"\"\n",
    "\n",
    "print(usage_guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfbfd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 14: Advanced ReAct Patterns ===\n",
    "print(\"=== é€²éš ReAct æ¨¡å¼ (Advanced ReAct Patterns) ===\")\n",
    "\n",
    "\n",
    "class AdvancedReActAgent(ReActAgent):\n",
    "    \"\"\"Enhanced ReAct agent with advanced patterns\"\"\"\n",
    "\n",
    "    def __init__(self, llm, tools: Dict[str, Any], max_iterations: int = 5):\n",
    "        super().__init__(llm, tools, max_iterations)\n",
    "        self.context_memory = []\n",
    "        self.tool_usage_stats = {}\n",
    "\n",
    "    def add_context(self, context: str):\n",
    "        \"\"\"Add contextual information to the agent\"\"\"\n",
    "        self.context_memory.append(context)\n",
    "\n",
    "    def get_tool_stats(self) -> Dict[str, int]:\n",
    "        \"\"\"Get tool usage statistics\"\"\"\n",
    "        return self.tool_usage_stats.copy()\n",
    "\n",
    "    def execute_tool_with_stats(self, tool_name: str, query: str) -> str:\n",
    "        \"\"\"Execute tool and track usage statistics\"\"\"\n",
    "        # Update stats\n",
    "        self.tool_usage_stats[tool_name] = self.tool_usage_stats.get(tool_name, 0) + 1\n",
    "\n",
    "        # Execute tool\n",
    "        result = self.execute_tool(tool_name, query)\n",
    "\n",
    "        # Log execution\n",
    "        print(f\"   ğŸ“Š Tool '{tool_name}' used {self.tool_usage_stats[tool_name]} times\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    def plan_decomposition(self, question: str) -> List[str]:\n",
    "        \"\"\"Decompose complex questions into sub-tasks\"\"\"\n",
    "        # Simple heuristic-based decomposition\n",
    "        if \"and\" in question.lower():\n",
    "            parts = question.split(\" and \")\n",
    "            return [part.strip() + \"?\" for part in parts]\n",
    "        elif \"compare\" in question.lower():\n",
    "            return [\n",
    "                \"Find information about the first item\",\n",
    "                \"Find information about the second item\",\n",
    "                \"Compare the two items\",\n",
    "            ]\n",
    "        else:\n",
    "            return [question]\n",
    "\n",
    "\n",
    "# Demonstrate advanced patterns\n",
    "advanced_agent = AdvancedReActAgent(llm, tools_dict)\n",
    "\n",
    "# Pattern 1: Question Decomposition\n",
    "complex_q = \"What is the population of Tokyo and how does it compare to New York?\"\n",
    "subtasks = advanced_agent.plan_decomposition(complex_q)\n",
    "\n",
    "print(\"ğŸ”€ Question Decomposition:\")\n",
    "print(f\"Original: {complex_q}\")\n",
    "print(\"Sub-tasks:\")\n",
    "for i, task in enumerate(subtasks, 1):\n",
    "    print(f\"  {i}. {task}\")\n",
    "\n",
    "# Pattern 2: Context-aware reasoning\n",
    "advanced_agent.add_context(\"User is interested in urban planning\")\n",
    "advanced_agent.add_context(\"Previous query was about city demographics\")\n",
    "\n",
    "print(f\"\\nğŸ§  Context Memory: {advanced_agent.context_memory}\")\n",
    "\n",
    "# Pattern 3: Tool usage monitoring\n",
    "print(\"\\nğŸ“ˆ Tool Usage Tracking:\")\n",
    "advanced_agent.execute_tool_with_stats(\"calculator\", \"100 + 200\")\n",
    "advanced_agent.execute_tool_with_stats(\"memory\", \"store,demo,value\")\n",
    "advanced_agent.execute_tool_with_stats(\"calculator\", \"300 * 2\")\n",
    "\n",
    "print(f\"Final stats: {advanced_agent.get_tool_stats()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a37279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 15: Real-world Application Example ===\n",
    "print(\"\\n=== å¯¦éš›æ‡‰ç”¨ç¯„ä¾‹ (Real-world Application) ===\")\n",
    "\n",
    "\n",
    "def financial_analysis_demo():\n",
    "    \"\"\"Demonstrate ReAct for financial analysis\"\"\"\n",
    "\n",
    "    print(\"ğŸ’° Financial Analysis Scenario\")\n",
    "    print(\"Question: Should I invest in renewable energy stocks?\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Simulated ReAct reasoning chain\n",
    "    steps = [\n",
    "        {\n",
    "            \"step\": 1,\n",
    "            \"thought\": \"I need current information about renewable energy market trends\",\n",
    "            \"action\": \"search: renewable energy stocks performance 2024\",\n",
    "            \"observation\": \"Renewable energy sector showed 15% growth in Q1 2024...\",\n",
    "        },\n",
    "        {\n",
    "            \"step\": 2,\n",
    "            \"thought\": \"Let me find specific company performances\",\n",
    "            \"action\": \"search: top renewable energy companies stock prices\",\n",
    "            \"observation\": \"Tesla (TSLA): +12%, NextEra Energy (NEE): +8%, Enphase: +20%...\",\n",
    "        },\n",
    "        {\n",
    "            \"step\": 3,\n",
    "            \"thought\": \"I should calculate potential returns based on different investment amounts\",\n",
    "            \"action\": \"calculator: 10000 * 1.15\",\n",
    "            \"observation\": \"Calculation: 10000 * 1.15 = 11500.0\",\n",
    "        },\n",
    "        {\n",
    "            \"step\": 4,\n",
    "            \"thought\": \"Let me store key findings for the final recommendation\",\n",
    "            \"action\": \"memory: store,sector_growth,15%\",\n",
    "            \"observation\": \"Stored: sector_growth = 15%\",\n",
    "        },\n",
    "        {\n",
    "            \"step\": 5,\n",
    "            \"thought\": \"Based on market data and calculations, I can provide a recommendation\",\n",
    "            \"action\": None,\n",
    "            \"observation\": None,\n",
    "            \"final_answer\": \"Based on current market data showing 15% sector growth and strong individual stock performance, renewable energy stocks appear promising. A $10,000 investment could potentially grow to $11,500 based on sector averages. However, consider diversification and your risk tolerance.\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for step_data in steps:\n",
    "        print(f\"\\nğŸ”¹ Step {step_data['step']}:\")\n",
    "        print(f\"   ğŸ’­ Thought: {step_data['thought']}\")\n",
    "\n",
    "        if step_data[\"action\"]:\n",
    "            print(f\"   ğŸ”§ Action: {step_data['action']}\")\n",
    "            print(f\"   ğŸ‘€ Observation: {step_data['observation']}\")\n",
    "\n",
    "        if \"final_answer\" in step_data:\n",
    "            print(f\"   âœ… Final Answer: {step_data['final_answer']}\")\n",
    "\n",
    "    return steps\n",
    "\n",
    "\n",
    "financial_demo = financial_analysis_demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d912f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 16: Integration with Other Systems ===\n",
    "print(\"\\n=== ç³»çµ±æ•´åˆç¯„ä¾‹ (System Integration) ===\")\n",
    "\n",
    "\n",
    "class IntegratedReActAgent(AdvancedReActAgent):\n",
    "    \"\"\"ReAct agent with external system integration capabilities\"\"\"\n",
    "\n",
    "    def __init__(self, llm, tools: Dict[str, Any], max_iterations: int = 5):\n",
    "        super().__init__(llm, tools, max_iterations)\n",
    "        self.external_apis = {}\n",
    "        self.data_sources = {}\n",
    "\n",
    "    def register_api(self, name: str, endpoint: str, headers: Dict = None):\n",
    "        \"\"\"Register external API for tool usage\"\"\"\n",
    "        self.external_apis[name] = {\"endpoint\": endpoint, \"headers\": headers or {}}\n",
    "        print(f\"ğŸ“¡ Registered API: {name}\")\n",
    "\n",
    "    def register_data_source(self, name: str, source_type: str, config: Dict):\n",
    "        \"\"\"Register data source (database, file, etc.)\"\"\"\n",
    "        self.data_sources[name] = {\"type\": source_type, \"config\": config}\n",
    "        print(f\"ğŸ—„ï¸ Registered data source: {name}\")\n",
    "\n",
    "    def export_reasoning_chain(self, format: str = \"json\") -> str:\n",
    "        \"\"\"Export reasoning chain for external analysis\"\"\"\n",
    "        if format == \"json\":\n",
    "            import json\n",
    "\n",
    "            return json.dumps(self.reasoning_chain, indent=2)\n",
    "        elif format == \"markdown\":\n",
    "            md_content = \"# ReAct Reasoning Chain\\n\\n\"\n",
    "            for i, step in enumerate(self.reasoning_chain, 1):\n",
    "                md_content += f\"## Step {i}\\n\"\n",
    "                if \"response\" in step:\n",
    "                    md_content += f\"**Response:** {step['response']}\\n\\n\"\n",
    "                if \"action\" in step and step[\"action\"]:\n",
    "                    md_content += f\"**Action:** {step['action']}\\n\\n\"\n",
    "                if \"observation\" in step:\n",
    "                    md_content += f\"**Observation:** {step['observation']}\\n\\n\"\n",
    "            return md_content\n",
    "        else:\n",
    "            return str(self.reasoning_chain)\n",
    "\n",
    "\n",
    "# Demo integration capabilities\n",
    "integrated_agent = IntegratedReActAgent(llm, tools_dict)\n",
    "\n",
    "# Register sample integrations\n",
    "integrated_agent.register_api(\"weather_api\", \"https://api.weather.com/v1/current\")\n",
    "integrated_agent.register_data_source(\n",
    "    \"user_db\", \"postgresql\", {\"host\": \"localhost\", \"db\": \"users\"}\n",
    ")\n",
    "\n",
    "print(\"Integration setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2dc8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 17: Performance Monitoring ===\n",
    "import time\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    \"\"\"Monitor ReAct agent performance metrics\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            \"total_queries\": 0,\n",
    "            \"successful_queries\": 0,\n",
    "            \"average_iterations\": 0,\n",
    "            \"average_response_time\": 0,\n",
    "            \"tool_usage\": {},\n",
    "            \"error_count\": 0,\n",
    "        }\n",
    "        self.query_logs = []\n",
    "\n",
    "    def start_query(self, query: str) -> Dict:\n",
    "        \"\"\"Start monitoring a query\"\"\"\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"start_time\": time.time(),\n",
    "            \"iterations\": 0,\n",
    "            \"tools_used\": [],\n",
    "            \"errors\": [],\n",
    "        }\n",
    "\n",
    "    def log_tool_usage(self, log_entry: Dict, tool_name: str):\n",
    "        \"\"\"Log tool usage in current query\"\"\"\n",
    "        log_entry[\"tools_used\"].append(tool_name)\n",
    "        self.metrics[\"tool_usage\"][tool_name] = (\n",
    "            self.metrics[\"tool_usage\"].get(tool_name, 0) + 1\n",
    "        )\n",
    "\n",
    "    def log_error(self, log_entry: Dict, error: str):\n",
    "        \"\"\"Log error in current query\"\"\"\n",
    "        log_entry[\"errors\"].append(error)\n",
    "        self.metrics[\"error_count\"] += 1\n",
    "\n",
    "    def finish_query(self, log_entry: Dict, success: bool):\n",
    "        \"\"\"Finish monitoring a query and update metrics\"\"\"\n",
    "        log_entry[\"end_time\"] = time.time()\n",
    "        log_entry[\"duration\"] = log_entry[\"end_time\"] - log_entry[\"start_time\"]\n",
    "        log_entry[\"success\"] = success\n",
    "\n",
    "        self.query_logs.append(log_entry)\n",
    "        self.metrics[\"total_queries\"] += 1\n",
    "\n",
    "        if success:\n",
    "            self.metrics[\"successful_queries\"] += 1\n",
    "\n",
    "        # Update averages\n",
    "        self._update_averages()\n",
    "\n",
    "    def _update_averages(self):\n",
    "        \"\"\"Update average metrics\"\"\"\n",
    "        if self.query_logs:\n",
    "            total_iterations = sum(log.get(\"iterations\", 0) for log in self.query_logs)\n",
    "            total_time = sum(log.get(\"duration\", 0) for log in self.query_logs)\n",
    "\n",
    "            self.metrics[\"average_iterations\"] = total_iterations / len(self.query_logs)\n",
    "            self.metrics[\"average_response_time\"] = total_time / len(self.query_logs)\n",
    "\n",
    "    def get_report(self) -> str:\n",
    "        \"\"\"Generate performance report\"\"\"\n",
    "        success_rate = (\n",
    "            (self.metrics[\"successful_queries\"] / self.metrics[\"total_queries\"] * 100)\n",
    "            if self.metrics[\"total_queries\"] > 0\n",
    "            else 0\n",
    "        )\n",
    "\n",
    "        report = f\"\"\"\n",
    "ğŸ“Š ReAct Performance Report\n",
    "==========================\n",
    "Total Queries: {self.metrics['total_queries']}\n",
    "Successful: {self.metrics['successful_queries']} ({success_rate:.1f}%)\n",
    "Average Iterations: {self.metrics['average_iterations']:.1f}\n",
    "Average Response Time: {self.metrics['average_response_time']:.2f}s\n",
    "Errors: {self.metrics['error_count']}\n",
    "\n",
    "Tool Usage:\n",
    "{chr(10).join(f'  {tool}: {count}' for tool, count in self.metrics['tool_usage'].items())}\n",
    "\"\"\"\n",
    "        return report\n",
    "\n",
    "\n",
    "# Demo performance monitoring\n",
    "monitor = PerformanceMonitor()\n",
    "\n",
    "# Simulate some queries\n",
    "for i in range(3):\n",
    "    log = monitor.start_query(f\"Sample query {i+1}\")\n",
    "    log[\"iterations\"] = i + 2\n",
    "    monitor.log_tool_usage(log, \"search\")\n",
    "    monitor.log_tool_usage(log, \"calculator\")\n",
    "    if i == 2:  # Simulate error in last query\n",
    "        monitor.log_error(log, \"Tool timeout\")\n",
    "    monitor.finish_query(log, success=(i != 2))\n",
    "    time.sleep(0.1)  # Small delay for realistic timing\n",
    "\n",
    "print(monitor.get_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ab29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 18: Best Practices Summary ===\n",
    "print(\"=== æœ€ä½³å¯¦è¸ç¸½çµ (Best Practices Summary) ===\")\n",
    "\n",
    "best_practices = {\n",
    "    \"è¨­è¨ˆåŸå‰‡ (Design Principles)\": [\n",
    "        \"ä¿æŒå·¥å…·åŠŸèƒ½å–®ä¸€ä¸”æ˜ç¢º\",\n",
    "        \"å¯¦ä½œå¥å…¨çš„éŒ¯èª¤è™•ç†æ©Ÿåˆ¶\",\n",
    "        \"ä½¿ç”¨çµæ§‹åŒ–çš„æç¤ºæ ¼å¼\",\n",
    "        \"é™åˆ¶æœ€å¤§è¿­ä»£æ¬¡æ•¸é˜²æ­¢ç„¡é™å¾ªç’°\",\n",
    "        \"æä¾›æ¸…æ™°çš„å·¥å…·ä½¿ç”¨èªªæ˜\",\n",
    "    ],\n",
    "    \"æ€§èƒ½å„ªåŒ– (Performance Optimization)\": [\n",
    "        \"å¿«å–å¸¸ç”¨æŸ¥è©¢çµæœ\",\n",
    "        \"ä¸¦è¡ŒåŸ·è¡Œç¨ç«‹å·¥å…·èª¿ç”¨\",\n",
    "        \"ä½¿ç”¨è¼•é‡ç´šæ¨¡å‹é€²è¡Œç°¡å–®ä»»å‹™\",\n",
    "        \"å¯¦ä½œæ™ºèƒ½æå‰çµ‚æ­¢æ©Ÿåˆ¶\",\n",
    "        \"ç›£æ§å’Œåˆ†æå·¥å…·ä½¿ç”¨æ¨¡å¼\",\n",
    "    ],\n",
    "    \"å¯é æ€§ (Reliability)\": [\n",
    "        \"å¯¦ä½œé‡è©¦æ©Ÿåˆ¶è™•ç†æš«æ™‚æ€§éŒ¯èª¤\",\n",
    "        \"æä¾›é™ç´šç­–ç•¥ç•¶ä¸»è¦å·¥å…·å¤±æ•ˆ\",\n",
    "        \"é©—è­‰å·¥å…·è¼¸å‡ºæ ¼å¼å’Œå…§å®¹\",\n",
    "        \"è¨˜éŒ„è©³ç´°çš„åŸ·è¡Œæ—¥èªŒ\",\n",
    "        \"å®šæœŸæ¸¬è©¦æ‰€æœ‰å·¥å…·åŠŸèƒ½\",\n",
    "    ],\n",
    "    \"å¯ç¶­è­·æ€§ (Maintainability)\": [\n",
    "        \"æ¨¡çµ„åŒ–å·¥å…·è¨­è¨ˆä¾¿æ–¼æ“´å±•\",\n",
    "        \"ä½¿ç”¨é…ç½®æ–‡ä»¶ç®¡ç†å·¥å…·åƒæ•¸\",\n",
    "        \"æä¾›å®Œæ•´çš„æ–‡æª”å’Œç¯„ä¾‹\",\n",
    "        \"å¯¦ä½œè‡ªå‹•åŒ–æ¸¬è©¦å¥—ä»¶\",\n",
    "        \"ç‰ˆæœ¬æ§åˆ¶å·¥å…·å’Œæç¤ºæ¨¡æ¿\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "for category, practices in best_practices.items():\n",
    "    print(f\"\\nğŸ¯ {category}:\")\n",
    "    for practice in practices:\n",
    "        print(f\"   â€¢ {practice}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d2c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 19: Final Smoke Test ===\n",
    "def comprehensive_smoke_test():\n",
    "    \"\"\"Comprehensive smoke test for all ReAct components\"\"\"\n",
    "    print(\"ğŸ§ª ç¶œåˆæ¸¬è©¦ (Comprehensive Smoke Test)\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    test_results = {}\n",
    "\n",
    "    # Test 1: Basic ReAct functionality\n",
    "    try:\n",
    "        basic_agent = ReActAgent(llm, tools_dict, max_iterations=2)\n",
    "        test_results[\"basic_agent\"] = \"âœ… PASS\"\n",
    "    except Exception as e:\n",
    "        test_results[\"basic_agent\"] = f\"âŒ FAIL: {e}\"\n",
    "\n",
    "    # Test 2: Advanced agent features\n",
    "    try:\n",
    "        adv_agent = AdvancedReActAgent(llm, tools_dict)\n",
    "        adv_agent.add_context(\"test context\")\n",
    "        decomp = adv_agent.plan_decomposition(\"test question\")\n",
    "        test_results[\"advanced_features\"] = \"âœ… PASS\"\n",
    "    except Exception as e:\n",
    "        test_results[\"advanced_features\"] = f\"âŒ FAIL: {e}\"\n",
    "\n",
    "    # Test 3: Performance monitoring\n",
    "    try:\n",
    "        perf_monitor = PerformanceMonitor()\n",
    "        log = perf_monitor.start_query(\"test\")\n",
    "        perf_monitor.finish_query(log, True)\n",
    "        report = perf_monitor.get_report()\n",
    "        test_results[\"performance_monitoring\"] = \"âœ… PASS\"\n",
    "    except Exception as e:\n",
    "        test_results[\"performance_monitoring\"] = f\"âŒ FAIL: {e}\"\n",
    "\n",
    "    # Test 4: Integration capabilities\n",
    "    try:\n",
    "        int_agent = IntegratedReActAgent(llm, tools_dict)\n",
    "        int_agent.register_api(\"test_api\", \"http://test.com\")\n",
    "        export = int_agent.export_reasoning_chain(\"json\")\n",
    "        test_results[\"integration\"] = \"âœ… PASS\"\n",
    "    except Exception as e:\n",
    "        test_results[\"integration\"] = f\"âŒ FAIL: {e}\"\n",
    "\n",
    "    # Test 5: All tools functional\n",
    "    tool_tests = {}\n",
    "    for tool_name, tool in tools_dict.items():\n",
    "        try:\n",
    "            if tool_name == \"calculator\":\n",
    "                result = tool.execute(\"1 + 1\")\n",
    "                tool_tests[tool_name] = \"âœ… PASS\" if \"2\" in result else \"âŒ FAIL\"\n",
    "            elif tool_name == \"memory\":\n",
    "                tool.execute(\"store\", \"test\", \"value\")\n",
    "                result = tool.execute(\"retrieve\", \"test\")\n",
    "                tool_tests[tool_name] = \"âœ… PASS\" if \"value\" in result else \"âŒ FAIL\"\n",
    "            else:\n",
    "                # For search tool, just check it doesn't crash\n",
    "                result = tool.execute(\"test\")\n",
    "                tool_tests[tool_name] = \"âœ… PASS\"\n",
    "        except Exception as e:\n",
    "            tool_tests[tool_name] = f\"âŒ FAIL: {e}\"\n",
    "\n",
    "    # Print results\n",
    "    print(\"Core Components:\")\n",
    "    for test_name, result in test_results.items():\n",
    "        print(f\"  {result} {test_name}\")\n",
    "\n",
    "    print(\"\\nTool Tests:\")\n",
    "    for tool_name, result in tool_tests.items():\n",
    "        print(f\"  {result} {tool_name}\")\n",
    "\n",
    "    # Overall status\n",
    "    all_passed = all(\n",
    "        \"âœ…\" in result for result in {**test_results, **tool_tests}.values()\n",
    "    )\n",
    "    overall_status = \"âœ… ALL TESTS PASSED\" if all_passed else \"âš ï¸ SOME TESTS FAILED\"\n",
    "    print(f\"\\n{overall_status}\")\n",
    "\n",
    "    return {\"core\": test_results, \"tools\": tool_tests, \"overall\": all_passed}\n",
    "\n",
    "\n",
    "final_test_results = comprehensive_smoke_test()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“ Notebook nb14_react_multistep_reasoning.ipynb completed!\")\n",
    "print(\"âœ… Ready for Git commit and next stage planning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ccbc4b",
   "metadata": {},
   "source": [
    "\n",
    "## 6. æœ¬ç« å°çµ\n",
    "\n",
    "### ğŸ¯ å®Œæˆé …ç›® (Completed Items)\n",
    "- **ReAct æ ¸å¿ƒå¼•æ“**ï¼šå¯¦ä½œå®Œæ•´çš„ Reasoning-Acting å¾ªç’°æ©Ÿåˆ¶\n",
    "- **å·¥å…·ç”Ÿæ…‹ç³»çµ±**ï¼šæœå°‹ã€è¨ˆç®—ã€è¨˜æ†¶ä¸‰å¤§åŸºç¤å·¥å…·\n",
    "- **å¤šæ­¥æ¨ç†èƒ½åŠ›**ï¼šè¤‡é›œå•é¡Œåˆ†è§£èˆ‡é€æ­¥è§£æ±º\n",
    "- **éŒ¯èª¤æ¢å¾©æ©Ÿåˆ¶**ï¼šè™•ç†å·¥å…·å¤±æ•ˆèˆ‡æ¨ç†ä¸­æ–·\n",
    "- **æ€§èƒ½ç›£æ§**ï¼šè¿½è¹¤åŸ·è¡Œæ•ˆç‡èˆ‡å·¥å…·ä½¿ç”¨çµ±è¨ˆ\n",
    "- **å¯è¦–åŒ–ç•Œé¢**ï¼šæ¨ç†éˆå±•ç¤ºèˆ‡æ±ºç­–éç¨‹é€æ˜åŒ–\n",
    "\n",
    "### ğŸ§  æ ¸å¿ƒæ¦‚å¿µè¦é» (Key Concepts)\n",
    "- **Thought-Action-Observation å¾ªç’°**ï¼šReAct çš„æ ¸å¿ƒé‹ä½œæ¨¡å¼\n",
    "- **å·¥å…·æŠ½è±¡åŒ–**ï¼šçµ±ä¸€çš„å·¥å…·æ¥å£è¨­è¨ˆåŸå‰‡\n",
    "- **æ¨ç†ç­–ç•¥æ¯”è¼ƒ**ï¼šReAct vs CoT vs Direct çš„é©ç”¨å ´æ™¯\n",
    "- **éŒ¯èª¤è™•ç†ç­–ç•¥**ï¼šé‡è©¦ã€é™ç´šã€æå‰çµ‚æ­¢æ©Ÿåˆ¶\n",
    "- **æ€§èƒ½å„ªåŒ–æŠ€å·§**ï¼šå¿«å–ã€ä¸¦è¡Œã€æ™ºèƒ½çµ‚æ­¢\n",
    "\n",
    "### âš ï¸ å¸¸è¦‹é™·é˜± (Common Pitfalls)\n",
    "- **ç„¡é™å¾ªç’°é¢¨éšª**ï¼šå¿…é ˆè¨­ç½®æœ€å¤§è¿­ä»£æ¬¡æ•¸é™åˆ¶\n",
    "- **å·¥å…·èª¿ç”¨æ ¼å¼**ï¼šéœ€è¦åš´æ ¼çš„è§£æè¦å‰‡é¿å…æ ¼å¼éŒ¯èª¤\n",
    "- **ä¸Šä¸‹æ–‡é•·åº¦**ï¼šæ¨ç†éˆéé•·å¯èƒ½è¶…å‡ºæ¨¡å‹é™åˆ¶\n",
    "- **å·¥å…·å¯é æ€§**ï¼šå¤–éƒ¨APIå¯èƒ½å¤±æ•ˆéœ€è¦é™ç´šç­–ç•¥\n",
    "- **æˆæœ¬æ§åˆ¶**ï¼šå¤šæ­¥æ¨ç†æœƒå¢åŠ  token æ¶ˆè€—\n",
    "\n",
    "### ğŸš€ ä¸‹ä¸€æ­¥å»ºè­° (Next Steps)\n",
    "\n",
    "**ç«‹å³å¯è¡Œçš„æ“´å±•**ï¼š\n",
    "1. **æ›´å¤šå·¥å…·é¡å‹**ï¼šæª”æ¡ˆæ“ä½œã€è³‡æ–™åº«æŸ¥è©¢ã€API èª¿ç”¨\n",
    "2. **æ™ºèƒ½å·¥å…·é¸æ“‡**ï¼šæ ¹æ“šå•é¡Œé¡å‹è‡ªå‹•é¸æ“‡æœ€ä½³å·¥å…·çµ„åˆ\n",
    "3. **ä¸¦è¡Œæ¨ç†**ï¼šç¨ç«‹å­ä»»å‹™çš„ä¸¦è¡ŒåŸ·è¡Œ\n",
    "\n",
    "**æ•´åˆå…¶ä»– Notebook**ï¼š\n",
    "- **nb13 (Function Calling)**ï¼šæ•´åˆæ›´è±å¯Œçš„å·¥å…·åº«\n",
    "- **nb26 (RAG Basic)**ï¼šçµåˆæª¢ç´¢å¢å¼·ç”Ÿæˆ\n",
    "- **nb29 (Multi-Agent)**ï¼šå¤šä»£ç†å”ä½œæ¨ç†\n",
    "\n",
    "**å»ºè­°ä¸‹ä¸€å€‹é‡é»**ï¼š\n",
    "å»ºè­°å…ˆå®Œæˆ **nb29 Multi-Agent Collaboration**ï¼Œå› ç‚ºï¼š\n",
    "- ReAct ç‚ºå–®ä¸€ä»£ç†æ¨ç†ï¼Œå¤šä»£ç†æ˜¯è‡ªç„¶å»¶ä¼¸\n",
    "- å¯é‡ç”¨æœ¬ç« çš„å·¥å…·å’Œæ¨ç†æ¡†æ¶\n",
    "- ç‚ºå¾ŒçºŒçš„è‡ªå‹•åŒ–æµç¨‹ (nb30) æ‰“ä¸‹åŸºç¤\n",
    "\n",
    "æº–å‚™å¥½ç¹¼çºŒä¸‹ä¸€å€‹ Notebook çš„é–‹ç™¼ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
