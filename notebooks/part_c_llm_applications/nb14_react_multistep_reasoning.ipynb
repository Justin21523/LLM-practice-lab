{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a89a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === nb14_react_multistep_reasoning.ipynb ===\n",
    "# ReAct 多步推理 (ReAct Multi-step Reasoning)\n",
    "# 學習目標: 掌握 Reasoning-Acting 循環、工具鏈整合、複雜問題分解\n",
    "\n",
    "# === Cell 1: Shared Cache Bootstrap ===\n",
    "import os, torch, platform, pathlib\n",
    "\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"/mnt/ai/cache\")\n",
    "paths = {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}\n",
    "for k, v in paths.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"[Cache] Root:\", AI_CACHE_ROOT)\n",
    "print(\n",
    "    \"[GPU]\",\n",
    "    torch.cuda.is_available(),\n",
    "    torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5500078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 2: Install Dependencies ===\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install package if not already installed\"\"\"\n",
    "    try:\n",
    "        __import__(package.split(\"[\")[0])\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "\n",
    "# Install required packages\n",
    "packages = [\n",
    "    \"transformers>=4.36.0\",\n",
    "    \"accelerate\",\n",
    "    \"bitsandbytes\",\n",
    "    \"duckduckgo-search\",\n",
    "    \"beautifulsoup4\",\n",
    "    \"requests\",\n",
    "]\n",
    "\n",
    "for pkg in packages:\n",
    "    install_package(pkg)\n",
    "\n",
    "print(\"✅ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42786eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: ReAct 核心概念說明 ===\n",
    "\"\"\"\n",
    "## 🧠 ReAct 推理模式 (Reasoning and Acting)\n",
    "\n",
    "ReAct 是一種結合推理 (Reasoning) 與行動 (Acting) 的 AI 智能體模式：\n",
    "\n",
    "### 核心概念 (Core Concepts)\n",
    "- **Thought (思考)**：AI 分析當前狀況，制定下一步計畫\n",
    "- **Action (行動)**：執行具體工具調用 (搜尋、計算、檢索等)\n",
    "- **Observation (觀察)**：獲取行動結果，更新知識狀態\n",
    "- **Reasoning Chain (推理鏈)**：持續循環直到問題解決\n",
    "\n",
    "### 與其他模式比較\n",
    "- **Chain-of-Thought (CoT)**：純思維推理，缺乏外部工具\n",
    "- **Direct Generation**：直接生成答案，無推理過程\n",
    "- **ReAct**：思維 + 工具調用，適合複雜多步問題\n",
    "\n",
    "### 適用場景\n",
    "✅ 需要外部資訊的問題 (搜尋、計算)\n",
    "✅ 多步驟分解的複雜任務\n",
    "✅ 需要驗證與修正的推理過程\n",
    "❌ 純創意寫作或簡單問答\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a71719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 4: Basic Tools Definition ===\n",
    "import requests\n",
    "from typing import Dict, Any, List, Optional\n",
    "import json\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class SearchTool:\n",
    "    \"\"\"Web search tool using DuckDuckGo (no API key required)\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"search\"\n",
    "        self.description = \"Search the web for current information\"\n",
    "\n",
    "    def execute(self, query: str) -> str:\n",
    "        \"\"\"Execute web search and return results\"\"\"\n",
    "        try:\n",
    "            from duckduckgo_search import DDGS\n",
    "\n",
    "            with DDGS() as ddgs:\n",
    "                results = list(ddgs.text(query, max_results=3))\n",
    "\n",
    "            if not results:\n",
    "                return \"No search results found\"\n",
    "\n",
    "            formatted_results = []\n",
    "            for i, result in enumerate(results, 1):\n",
    "                formatted_results.append(\n",
    "                    f\"{i}. {result['title']}\\n\"\n",
    "                    f\"   {result['body'][:200]}...\\n\"\n",
    "                    f\"   Source: {result['href']}\\n\"\n",
    "                )\n",
    "\n",
    "            return \"\\n\".join(formatted_results)\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Search error: {str(e)}\"\n",
    "\n",
    "\n",
    "class CalculatorTool:\n",
    "    \"\"\"Mathematical calculation tool\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"calculator\"\n",
    "        self.description = \"Perform mathematical calculations\"\n",
    "\n",
    "    def execute(self, expression: str) -> str:\n",
    "        \"\"\"Execute mathematical calculation\"\"\"\n",
    "        try:\n",
    "            # Clean and validate expression\n",
    "            cleaned = re.sub(r\"[^0-9+\\-*/.() ]\", \"\", expression)\n",
    "\n",
    "            # Safe evaluation\n",
    "            result = eval(cleaned)\n",
    "            return f\"Calculation: {expression} = {result}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Calculation error: {str(e)}\"\n",
    "\n",
    "\n",
    "class MemoryTool:\n",
    "    \"\"\"Simple memory storage for conversation context\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"memory\"\n",
    "        self.description = \"Store and retrieve information\"\n",
    "        self.storage = {}\n",
    "\n",
    "    def execute(self, action: str, key: str = None, value: str = None) -> str:\n",
    "        \"\"\"Execute memory operations (store/retrieve)\"\"\"\n",
    "        try:\n",
    "            if action == \"store\" and key and value:\n",
    "                self.storage[key] = value\n",
    "                return f\"Stored: {key} = {value}\"\n",
    "\n",
    "            elif action == \"retrieve\" and key:\n",
    "                if key in self.storage:\n",
    "                    return f\"Retrieved: {key} = {self.storage[key]}\"\n",
    "                else:\n",
    "                    return f\"Key '{key}' not found in memory\"\n",
    "\n",
    "            elif action == \"list\":\n",
    "                if self.storage:\n",
    "                    items = [f\"{k}: {v}\" for k, v in self.storage.items()]\n",
    "                    return \"Memory contents:\\n\" + \"\\n\".join(items)\n",
    "                else:\n",
    "                    return \"Memory is empty\"\n",
    "\n",
    "            else:\n",
    "                return \"Invalid memory operation. Use: store/retrieve/list\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Memory error: {str(e)}\"\n",
    "\n",
    "\n",
    "# Initialize tools\n",
    "search_tool = SearchTool()\n",
    "calc_tool = CalculatorTool()\n",
    "memory_tool = MemoryTool()\n",
    "\n",
    "print(\"🛠️ Tools initialized:\")\n",
    "print(f\"- {search_tool.name}: {search_tool.description}\")\n",
    "print(f\"- {calc_tool.name}: {calc_tool.description}\")\n",
    "print(f\"- {memory_tool.name}: {memory_tool.description}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 5: LLM Adapter (Lightweight) ===\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "\n",
    "class SimpleLLMAdapter:\n",
    "    \"\"\"Lightweight LLM adapter for ReAct reasoning\"\"\"\n",
    "\n",
    "    def __init__(self, model_id: str = \"microsoft/DialoGPT-medium\"):\n",
    "        self.model_id = model_id\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        print(f\"Loading model: {model_id}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            load_in_4bit=torch.cuda.is_available(),  # Use 4bit if GPU available\n",
    "        )\n",
    "\n",
    "        # Add padding token if missing\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def generate(self, prompt: str, max_tokens: int = 256) -> str:\n",
    "        \"\"\"Generate response from prompt\"\"\"\n",
    "        try:\n",
    "            inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    inputs,\n",
    "                    max_new_tokens=max_tokens,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.7,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id,\n",
    "                    attention_mask=torch.ones_like(inputs),\n",
    "                )\n",
    "\n",
    "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "            # Extract only the new generation\n",
    "            if prompt in response:\n",
    "                response = response.replace(prompt, \"\").strip()\n",
    "\n",
    "            return response\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Generation error: {str(e)}\"\n",
    "\n",
    "\n",
    "# For demo purposes, we'll use a simple mock LLM\n",
    "class MockLLM:\n",
    "    \"\"\"Mock LLM for demonstration (replace with real LLM in production)\"\"\"\n",
    "\n",
    "    def generate(self, prompt: str, max_tokens: int = 256) -> str:\n",
    "        \"\"\"Generate mock responses based on prompt patterns\"\"\"\n",
    "        prompt_lower = prompt.lower()\n",
    "\n",
    "        if \"thought:\" in prompt_lower and \"search\" in prompt_lower:\n",
    "            return \"I need to search for current information about this topic.\"\n",
    "        elif \"thought:\" in prompt_lower and \"calculate\" in prompt_lower:\n",
    "            return \"I need to perform some mathematical calculations.\"\n",
    "        elif \"action:\" in prompt_lower:\n",
    "            return \"Executing the planned action...\"\n",
    "        else:\n",
    "            return \"Let me think about this step by step.\"\n",
    "\n",
    "\n",
    "# Use MockLLM for demo (replace with real LLM)\n",
    "llm = MockLLM()\n",
    "print(\"🤖 LLM adapter initialized (using mock for demo)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651d4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 6: ReAct Agent Core Implementation ===\n",
    "import re\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "\n",
    "class ReActAgent:\n",
    "    \"\"\"ReAct (Reasoning + Acting) Agent implementation\"\"\"\n",
    "\n",
    "    def __init__(self, llm, tools: Dict[str, Any], max_iterations: int = 5):\n",
    "        self.llm = llm\n",
    "        self.tools = tools\n",
    "        self.max_iterations = max_iterations\n",
    "        self.reasoning_chain = []\n",
    "\n",
    "    def parse_action(self, text: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "        \"\"\"Parse action from LLM response\"\"\"\n",
    "        # Look for Action[tool_name]: query pattern\n",
    "        action_pattern = r\"Action\\[([^\\]]+)\\]:\\s*(.+)\"\n",
    "        match = re.search(action_pattern, text, re.IGNORECASE)\n",
    "\n",
    "        if match:\n",
    "            tool_name = match.group(1).strip()\n",
    "            query = match.group(2).strip()\n",
    "            return tool_name, query\n",
    "\n",
    "        return None, None\n",
    "\n",
    "    def execute_tool(self, tool_name: str, query: str) -> str:\n",
    "        \"\"\"Execute tool with given query\"\"\"\n",
    "        if tool_name not in self.tools:\n",
    "            return f\"Error: Tool '{tool_name}' not found. Available tools: {list(self.tools.keys())}\"\n",
    "\n",
    "        tool = self.tools[tool_name]\n",
    "\n",
    "        try:\n",
    "            if tool_name == \"memory\":\n",
    "                # Parse memory operations\n",
    "                parts = query.split(\",\")\n",
    "                if len(parts) >= 2:\n",
    "                    action = parts[0].strip()\n",
    "                    key = parts[1].strip() if len(parts) > 1 else None\n",
    "                    value = parts[2].strip() if len(parts) > 2 else None\n",
    "                    return tool.execute(action, key, value)\n",
    "                else:\n",
    "                    return tool.execute(query)\n",
    "            else:\n",
    "                return tool.execute(query)\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Tool execution error: {str(e)}\"\n",
    "\n",
    "    def solve(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"Solve question using ReAct reasoning\"\"\"\n",
    "        self.reasoning_chain = []\n",
    "\n",
    "        # Initial prompt setup\n",
    "        system_prompt = \"\"\"You are an AI assistant that uses ReAct (Reasoning + Acting) to solve problems.\n",
    "\n",
    "Available tools:\n",
    "- search: Search the web for information\n",
    "- calculator: Perform mathematical calculations\n",
    "- memory: Store and retrieve information (actions: store,key,value or retrieve,key or list)\n",
    "\n",
    "Format your responses as:\n",
    "Thought: [Your reasoning about what to do next]\n",
    "Action[tool_name]: query\n",
    "Observation: [Tool result will be provided]\n",
    "\n",
    "Continue this cycle until you can provide a Final Answer.\n",
    "\n",
    "Example:\n",
    "Thought: I need to search for information about this topic.\n",
    "Action[search]: what is the capital of France\n",
    "Observation: [Search results will appear here]\n",
    "Thought: Based on the search results, I can now answer.\n",
    "Final Answer: The capital of France is Paris.\n",
    "\"\"\"\n",
    "\n",
    "        current_prompt = f\"{system_prompt}\\n\\nQuestion: {question}\\n\\n\"\n",
    "\n",
    "        for iteration in range(self.max_iterations):\n",
    "            print(f\"\\n=== Iteration {iteration + 1} ===\")\n",
    "\n",
    "            # Generate reasoning\n",
    "            response = self.llm.generate(current_prompt, max_tokens=256)\n",
    "            print(f\"Response: {response}\")\n",
    "\n",
    "            # Record step\n",
    "            step = {\n",
    "                \"iteration\": iteration + 1,\n",
    "                \"prompt\": current_prompt,\n",
    "                \"response\": response,\n",
    "                \"action\": None,\n",
    "                \"observation\": None,\n",
    "            }\n",
    "\n",
    "            # Check for final answer\n",
    "            if \"final answer:\" in response.lower():\n",
    "                step[\"final_answer\"] = True\n",
    "                self.reasoning_chain.append(step)\n",
    "\n",
    "                # Extract final answer\n",
    "                final_answer_match = re.search(\n",
    "                    r\"final answer:\\s*(.+)\", response, re.IGNORECASE\n",
    "                )\n",
    "                final_answer = (\n",
    "                    final_answer_match.group(1) if final_answer_match else response\n",
    "                )\n",
    "\n",
    "                return {\n",
    "                    \"success\": True,\n",
    "                    \"answer\": final_answer,\n",
    "                    \"reasoning_chain\": self.reasoning_chain,\n",
    "                    \"iterations\": iteration + 1,\n",
    "                }\n",
    "\n",
    "            # Parse and execute action\n",
    "            tool_name, query = self.parse_action(response)\n",
    "\n",
    "            if tool_name and query:\n",
    "                print(f\"Executing: {tool_name}({query})\")\n",
    "\n",
    "                observation = self.execute_tool(tool_name, query)\n",
    "                print(f\"Observation: {observation}\")\n",
    "\n",
    "                step[\"action\"] = {\"tool\": tool_name, \"query\": query}\n",
    "                step[\"observation\"] = observation\n",
    "\n",
    "                # Update prompt with observation\n",
    "                current_prompt += f\"{response}\\nObservation: {observation}\\n\\n\"\n",
    "\n",
    "            else:\n",
    "                # No action found, continue with reasoning\n",
    "                current_prompt += f\"{response}\\n\\n\"\n",
    "\n",
    "            self.reasoning_chain.append(step)\n",
    "\n",
    "        # Max iterations reached\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"answer\": \"Maximum iterations reached without finding answer\",\n",
    "            \"reasoning_chain\": self.reasoning_chain,\n",
    "            \"iterations\": self.max_iterations,\n",
    "        }\n",
    "\n",
    "\n",
    "# Initialize ReAct agent\n",
    "tools_dict = {\"search\": search_tool, \"calculator\": calc_tool, \"memory\": memory_tool}\n",
    "\n",
    "react_agent = ReActAgent(llm, tools_dict, max_iterations=5)\n",
    "print(\"🧠 ReAct Agent initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904fa364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 7: Simple Reasoning Example ===\n",
    "print(\"=== 簡單推理範例 (Simple Reasoning Example) ===\")\n",
    "\n",
    "# Example 1: Direct calculation\n",
    "simple_question = \"What is 15% of 2,500?\"\n",
    "\n",
    "print(f\"Question: {simple_question}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Manual ReAct simulation for demo\n",
    "print(\"Thought: I need to calculate 15% of 2,500\")\n",
    "print(\"Action[calculator]: 2500 * 0.15\")\n",
    "\n",
    "calc_result = calc_tool.execute(\"2500 * 0.15\")\n",
    "print(f\"Observation: {calc_result}\")\n",
    "\n",
    "print(\"Thought: The calculation is complete\")\n",
    "print(\"Final Answer: 15% of 2,500 is 375\")\n",
    "\n",
    "print(\"\\n✅ Simple reasoning completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03462cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 8: Multi-step Reasoning Example ===\n",
    "print(\"=== 多步推理範例 (Multi-step Reasoning Example) ===\")\n",
    "\n",
    "# Complex question requiring multiple steps\n",
    "complex_question = \"If I invest $10,000 at 3% annual interest compounded annually, how much will I have after 5 years?\"\n",
    "\n",
    "print(f\"Question: {complex_question}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Step 1: Store initial values\n",
    "print(\n",
    "    \"Thought: I need to solve a compound interest problem. Let me store the given values first.\"\n",
    ")\n",
    "print(\"Action[memory]: store,principal,10000\")\n",
    "memory_result1 = memory_tool.execute(\"store\", \"principal\", \"10000\")\n",
    "print(f\"Observation: {memory_result1}\")\n",
    "\n",
    "print(\"Action[memory]: store,rate,0.03\")\n",
    "memory_result2 = memory_tool.execute(\"store\", \"rate\", \"0.03\")\n",
    "print(f\"Observation: {memory_result2}\")\n",
    "\n",
    "print(\"Action[memory]: store,time,5\")\n",
    "memory_result3 = memory_tool.execute(\"store\", \"time\", \"5\")\n",
    "print(f\"Observation: {memory_result3}\")\n",
    "\n",
    "# Step 2: Apply compound interest formula\n",
    "print(\n",
    "    \"\\nThought: Now I'll calculate using the compound interest formula: A = P(1 + r)^t\"\n",
    ")\n",
    "print(\"Action[calculator]: 10000 * (1.03 ** 5)\")\n",
    "compound_result = calc_tool.execute(\"10000 * (1.03 ** 5)\")\n",
    "print(f\"Observation: {compound_result}\")\n",
    "\n",
    "# Step 3: Calculate interest earned\n",
    "print(\"\\nThought: Let me also calculate the interest earned\")\n",
    "print(\"Action[calculator]: 11592.74 - 10000\")\n",
    "interest_result = calc_tool.execute(\"11592.74 - 10000\")\n",
    "print(f\"Observation: {interest_result}\")\n",
    "\n",
    "print(\"\\nThought: I have all the information needed to provide a complete answer\")\n",
    "print(\n",
    "    \"Final Answer: After 5 years, your $10,000 investment at 3% annual compound interest will grow to approximately $11,592.74, earning $1,592.74 in interest.\"\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Multi-step reasoning completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b1a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 9: Reasoning Chain Visualization ===\n",
    "def visualize_reasoning_chain(steps: List[Dict], title: str = \"Reasoning Chain\"):\n",
    "    \"\"\"Visualize the reasoning process\"\"\"\n",
    "    print(f\"\\n📊 {title}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for i, step in enumerate(steps, 1):\n",
    "        print(f\"\\n🔹 Step {i}:\")\n",
    "\n",
    "        if \"thought\" in step:\n",
    "            print(f\"   💭 Thought: {step['thought']}\")\n",
    "\n",
    "        if \"action\" in step and step[\"action\"]:\n",
    "            action = step[\"action\"]\n",
    "            print(f\"   🔧 Action: {action['tool']}({action['query']})\")\n",
    "\n",
    "        if \"observation\" in step and step[\"observation\"]:\n",
    "            obs = (\n",
    "                step[\"observation\"][:100] + \"...\"\n",
    "                if len(step[\"observation\"]) > 100\n",
    "                else step[\"observation\"]\n",
    "            )\n",
    "            print(f\"   👀 Observation: {obs}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "# Simulate a reasoning chain for visualization\n",
    "demo_chain = [\n",
    "    {\n",
    "        \"thought\": \"I need to find current information about this topic\",\n",
    "        \"action\": {\"tool\": \"search\", \"query\": \"latest developments in AI\"},\n",
    "        \"observation\": \"Found 3 recent articles about AI developments...\",\n",
    "    },\n",
    "    {\n",
    "        \"thought\": \"Now I need to calculate some values based on the information\",\n",
    "        \"action\": {\"tool\": \"calculator\", \"query\": \"1000 * 1.05\"},\n",
    "        \"observation\": \"Calculation: 1000 * 1.05 = 1050.0\",\n",
    "    },\n",
    "    {\n",
    "        \"thought\": \"Let me store this result for later reference\",\n",
    "        \"action\": {\"tool\": \"memory\", \"query\": \"store,result,1050\"},\n",
    "        \"observation\": \"Stored: result = 1050\",\n",
    "    },\n",
    "]\n",
    "\n",
    "visualize_reasoning_chain(demo_chain, \"示例推理鏈 (Example Reasoning Chain)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a203377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 10: Error Handling and Recovery ===\n",
    "print(\"=== 錯誤處理與恢復機制 (Error Handling & Recovery) ===\")\n",
    "\n",
    "\n",
    "class RobustReActAgent(ReActAgent):\n",
    "    \"\"\"Enhanced ReAct agent with error handling\"\"\"\n",
    "\n",
    "    def __init__(self, llm, tools: Dict[str, Any], max_iterations: int = 5):\n",
    "        super().__init__(llm, tools, max_iterations)\n",
    "        self.error_count = 0\n",
    "        self.max_errors = 3\n",
    "\n",
    "    def handle_error(self, error_msg: str, step: int) -> str:\n",
    "        \"\"\"Handle errors and suggest recovery actions\"\"\"\n",
    "        self.error_count += 1\n",
    "\n",
    "        recovery_strategies = [\n",
    "            \"Let me try a different approach to this problem.\",\n",
    "            \"I'll reformulate my query and try again.\",\n",
    "            \"Let me break this down into smaller steps.\",\n",
    "        ]\n",
    "\n",
    "        if self.error_count <= self.max_errors:\n",
    "            strategy = recovery_strategies[\n",
    "                (self.error_count - 1) % len(recovery_strategies)\n",
    "            ]\n",
    "            return f\"Error encountered: {error_msg}\\nRecovery: {strategy}\"\n",
    "        else:\n",
    "            return f\"Too many errors ({self.error_count}). Unable to continue.\"\n",
    "\n",
    "    def execute_tool_safe(self, tool_name: str, query: str) -> str:\n",
    "        \"\"\"Execute tool with error handling\"\"\"\n",
    "        try:\n",
    "            result = self.execute_tool(tool_name, query)\n",
    "\n",
    "            # Check for error indicators\n",
    "            if \"error\" in result.lower():\n",
    "                return self.handle_error(result, len(self.reasoning_chain))\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            return self.handle_error(str(e), len(self.reasoning_chain))\n",
    "\n",
    "\n",
    "# Demonstrate error handling\n",
    "robust_agent = RobustReActAgent(llm, tools_dict)\n",
    "\n",
    "print(\"Testing error handling:\")\n",
    "print(\"1. Invalid tool name\")\n",
    "error_result = robust_agent.execute_tool_safe(\"invalid_tool\", \"test query\")\n",
    "print(f\"   Result: {error_result}\")\n",
    "\n",
    "print(\"\\n2. Invalid calculation\")\n",
    "error_result2 = robust_agent.execute_tool_safe(\"calculator\", \"invalid_expression!!!\")\n",
    "print(f\"   Result: {error_result2}\")\n",
    "\n",
    "print(\"\\n✅ Error handling demonstrated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e69a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 11: Comparison of Reasoning Strategies ===\n",
    "def compare_reasoning_strategies():\n",
    "    \"\"\"Compare different reasoning approaches\"\"\"\n",
    "\n",
    "    question = \"What's the population of Tokyo and how does it compare to New York?\"\n",
    "\n",
    "    print(\"=== 推理策略比較 (Reasoning Strategy Comparison) ===\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    # 1. Direct Generation\n",
    "    print(\"\\n🎯 Direct Generation:\")\n",
    "    print(\n",
    "        \"   Response: Tokyo has about 14 million people, while New York has about 8.3 million.\"\n",
    "    )\n",
    "    print(\"   Pros: Fast, simple\")\n",
    "    print(\"   Cons: May be outdated, no verification\")\n",
    "\n",
    "    # 2. Chain-of-Thought\n",
    "    print(\"\\n🔗 Chain-of-Thought:\")\n",
    "    print(\"   Thought: I need to consider both cities' populations...\")\n",
    "    print(\"   Thought: Tokyo is the capital of Japan, a major metropolitan area...\")\n",
    "    print(\"   Thought: New York is the largest city in the US...\")\n",
    "    print(\"   Response: Based on my knowledge, Tokyo has more people than New York.\")\n",
    "    print(\"   Pros: Shows reasoning process\")\n",
    "    print(\"   Cons: Still no external verification\")\n",
    "\n",
    "    # 3. ReAct\n",
    "    print(\"\\n🧠 ReAct:\")\n",
    "    print(\"   Thought: I need current population data for both cities\")\n",
    "    print(\"   Action[search]: Tokyo population 2024\")\n",
    "    print(\"   Observation: [Current search results]\")\n",
    "    print(\"   Thought: Now I need New York population data\")\n",
    "    print(\"   Action[search]: New York population 2024\")\n",
    "    print(\"   Observation: [Current search results]\")\n",
    "    print(\"   Thought: Let me calculate the difference\")\n",
    "    print(\"   Action[calculator]: tokyo_pop - ny_pop\")\n",
    "    print(\"   Final Answer: [Answer with current, verified data]\")\n",
    "    print(\"   Pros: Current data, verifiable, transparent process\")\n",
    "    print(\"   Cons: Slower, requires tools\")\n",
    "\n",
    "    return {\n",
    "        \"direct\": {\"speed\": \"fast\", \"accuracy\": \"medium\", \"transparency\": \"low\"},\n",
    "        \"cot\": {\"speed\": \"medium\", \"accuracy\": \"medium\", \"transparency\": \"high\"},\n",
    "        \"react\": {\"speed\": \"slow\", \"accuracy\": \"high\", \"transparency\": \"high\"},\n",
    "    }\n",
    "\n",
    "\n",
    "strategy_comparison = compare_reasoning_strategies()\n",
    "print(f\"\\n📊 Strategy Analysis: {strategy_comparison}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a8003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 12: Smoke Test ===\n",
    "def smoke_test_react():\n",
    "    \"\"\"Quick smoke test for ReAct functionality\"\"\"\n",
    "    print(\"🧪 ReAct Smoke Test\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Test 1: Tool availability\n",
    "    required_tools = [\"search\", \"calculator\", \"memory\"]\n",
    "    available_tools = list(tools_dict.keys())\n",
    "\n",
    "    print(\"1. Tool Availability:\")\n",
    "    for tool in required_tools:\n",
    "        status = \"✅\" if tool in available_tools else \"❌\"\n",
    "        print(f\"   {status} {tool}\")\n",
    "\n",
    "    # Test 2: Basic tool execution\n",
    "    print(\"\\n2. Tool Execution:\")\n",
    "\n",
    "    # Calculator test\n",
    "    calc_test = calc_tool.execute(\"2 + 2\")\n",
    "    calc_status = \"✅\" if \"4\" in calc_test else \"❌\"\n",
    "    print(f\"   {calc_status} Calculator: {calc_test}\")\n",
    "\n",
    "    # Memory test\n",
    "    memory_tool.execute(\"store\", \"test_key\", \"test_value\")\n",
    "    memory_test = memory_tool.execute(\"retrieve\", \"test_key\")\n",
    "    memory_status = \"✅\" if \"test_value\" in memory_test else \"❌\"\n",
    "    print(f\"   {memory_status} Memory: {memory_test}\")\n",
    "\n",
    "    # Test 3: Action parsing\n",
    "    print(\"\\n3. Action Parsing:\")\n",
    "    test_response = \"Action[calculator]: 10 + 5\"\n",
    "    tool_name, query = react_agent.parse_action(test_response)\n",
    "    parse_status = \"✅\" if tool_name == \"calculator\" and query == \"10 + 5\" else \"❌\"\n",
    "    print(f\"   {parse_status} Parse: {tool_name}, {query}\")\n",
    "\n",
    "    # Test 4: LLM basic generation\n",
    "    print(\"\\n4. LLM Generation:\")\n",
    "    llm_test = llm.generate(\"Test prompt\")\n",
    "    llm_status = \"✅\" if llm_test and len(llm_test) > 0 else \"❌\"\n",
    "    print(f\"   {llm_status} LLM: Generated {len(llm_test)} characters\")\n",
    "\n",
    "    print(\"\\n✅ Smoke test completed\")\n",
    "\n",
    "\n",
    "smoke_test_react()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a9217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 13: Usage Examples and Best Practices ===\n",
    "print(\"=== 使用範例與最佳實踐 (Usage Examples & Best Practices) ===\")\n",
    "\n",
    "usage_guide = \"\"\"\n",
    "## 🎯 ReAct 適用場景 (When to Use ReAct)\n",
    "\n",
    "✅ **適合使用 ReAct**:\n",
    "• 需要最新資訊的問題 (股價、新聞、天氣)\n",
    "• 多步計算或分析任務\n",
    "• 需要驗證事實的查詢\n",
    "• 複雜問題分解 (研究報告、比較分析)\n",
    "• 需要工具輔助的任務 (檔案操作、API 調用)\n",
    "\n",
    "❌ **不適合使用 ReAct**:\n",
    "• 簡單創意寫作\n",
    "• 純邏輯推理問題 (數學證明)\n",
    "• 即時對話 (延遲敏感)\n",
    "• 已知答案的基礎問題\n",
    "\n",
    "## 🛠️ 工具設計原則 (Tool Design Principles)\n",
    "\n",
    "1. **單一職責**: 每個工具專注一個功能\n",
    "2. **錯誤處理**: 優雅處理異常情況\n",
    "3. **明確輸出**: 結構化、可解析的結果\n",
    "4. **狀態無關**: 工具調用應該是無狀態的\n",
    "5. **快速響應**: 避免長時間阻塞操作\n",
    "\n",
    "## ⚡ 性能優化建議 (Performance Tips)\n",
    "\n",
    "• **限制迭代次數**: 防止無限循環\n",
    "• **快取結果**: 避免重複工具調用\n",
    "• **並行執行**: 獨立工具可並行調用\n",
    "• **提前終止**: 檢測到答案時立即停止\n",
    "• **輕量級 LLM**: 使用適合任務大小的模型\n",
    "\n",
    "## 🐛 常見問題與解決方案 (Common Issues)\n",
    "\n",
    "1. **無限循環**: 設置最大迭代次數，檢測重複模式\n",
    "2. **工具調用失敗**: 實作重試機制和降級策略\n",
    "3. **解析錯誤**: 使用更嚴格的格式檢查\n",
    "4. **記憶體洩漏**: 定期清理推理鏈和工具狀態\n",
    "5. **回應格式不一致**: 使用結構化提示和格式驗證\n",
    "\"\"\"\n",
    "\n",
    "print(usage_guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfbfd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 14: Advanced ReAct Patterns ===\n",
    "print(\"=== 進階 ReAct 模式 (Advanced ReAct Patterns) ===\")\n",
    "\n",
    "\n",
    "class AdvancedReActAgent(ReActAgent):\n",
    "    \"\"\"Enhanced ReAct agent with advanced patterns\"\"\"\n",
    "\n",
    "    def __init__(self, llm, tools: Dict[str, Any], max_iterations: int = 5):\n",
    "        super().__init__(llm, tools, max_iterations)\n",
    "        self.context_memory = []\n",
    "        self.tool_usage_stats = {}\n",
    "\n",
    "    def add_context(self, context: str):\n",
    "        \"\"\"Add contextual information to the agent\"\"\"\n",
    "        self.context_memory.append(context)\n",
    "\n",
    "    def get_tool_stats(self) -> Dict[str, int]:\n",
    "        \"\"\"Get tool usage statistics\"\"\"\n",
    "        return self.tool_usage_stats.copy()\n",
    "\n",
    "    def execute_tool_with_stats(self, tool_name: str, query: str) -> str:\n",
    "        \"\"\"Execute tool and track usage statistics\"\"\"\n",
    "        # Update stats\n",
    "        self.tool_usage_stats[tool_name] = self.tool_usage_stats.get(tool_name, 0) + 1\n",
    "\n",
    "        # Execute tool\n",
    "        result = self.execute_tool(tool_name, query)\n",
    "\n",
    "        # Log execution\n",
    "        print(f\"   📊 Tool '{tool_name}' used {self.tool_usage_stats[tool_name]} times\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    def plan_decomposition(self, question: str) -> List[str]:\n",
    "        \"\"\"Decompose complex questions into sub-tasks\"\"\"\n",
    "        # Simple heuristic-based decomposition\n",
    "        if \"and\" in question.lower():\n",
    "            parts = question.split(\" and \")\n",
    "            return [part.strip() + \"?\" for part in parts]\n",
    "        elif \"compare\" in question.lower():\n",
    "            return [\n",
    "                \"Find information about the first item\",\n",
    "                \"Find information about the second item\",\n",
    "                \"Compare the two items\",\n",
    "            ]\n",
    "        else:\n",
    "            return [question]\n",
    "\n",
    "\n",
    "# Demonstrate advanced patterns\n",
    "advanced_agent = AdvancedReActAgent(llm, tools_dict)\n",
    "\n",
    "# Pattern 1: Question Decomposition\n",
    "complex_q = \"What is the population of Tokyo and how does it compare to New York?\"\n",
    "subtasks = advanced_agent.plan_decomposition(complex_q)\n",
    "\n",
    "print(\"🔀 Question Decomposition:\")\n",
    "print(f\"Original: {complex_q}\")\n",
    "print(\"Sub-tasks:\")\n",
    "for i, task in enumerate(subtasks, 1):\n",
    "    print(f\"  {i}. {task}\")\n",
    "\n",
    "# Pattern 2: Context-aware reasoning\n",
    "advanced_agent.add_context(\"User is interested in urban planning\")\n",
    "advanced_agent.add_context(\"Previous query was about city demographics\")\n",
    "\n",
    "print(f\"\\n🧠 Context Memory: {advanced_agent.context_memory}\")\n",
    "\n",
    "# Pattern 3: Tool usage monitoring\n",
    "print(\"\\n📈 Tool Usage Tracking:\")\n",
    "advanced_agent.execute_tool_with_stats(\"calculator\", \"100 + 200\")\n",
    "advanced_agent.execute_tool_with_stats(\"memory\", \"store,demo,value\")\n",
    "advanced_agent.execute_tool_with_stats(\"calculator\", \"300 * 2\")\n",
    "\n",
    "print(f\"Final stats: {advanced_agent.get_tool_stats()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a37279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 15: Real-world Application Example ===\n",
    "print(\"\\n=== 實際應用範例 (Real-world Application) ===\")\n",
    "\n",
    "\n",
    "def financial_analysis_demo():\n",
    "    \"\"\"Demonstrate ReAct for financial analysis\"\"\"\n",
    "\n",
    "    print(\"💰 Financial Analysis Scenario\")\n",
    "    print(\"Question: Should I invest in renewable energy stocks?\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Simulated ReAct reasoning chain\n",
    "    steps = [\n",
    "        {\n",
    "            \"step\": 1,\n",
    "            \"thought\": \"I need current information about renewable energy market trends\",\n",
    "            \"action\": \"search: renewable energy stocks performance 2024\",\n",
    "            \"observation\": \"Renewable energy sector showed 15% growth in Q1 2024...\",\n",
    "        },\n",
    "        {\n",
    "            \"step\": 2,\n",
    "            \"thought\": \"Let me find specific company performances\",\n",
    "            \"action\": \"search: top renewable energy companies stock prices\",\n",
    "            \"observation\": \"Tesla (TSLA): +12%, NextEra Energy (NEE): +8%, Enphase: +20%...\",\n",
    "        },\n",
    "        {\n",
    "            \"step\": 3,\n",
    "            \"thought\": \"I should calculate potential returns based on different investment amounts\",\n",
    "            \"action\": \"calculator: 10000 * 1.15\",\n",
    "            \"observation\": \"Calculation: 10000 * 1.15 = 11500.0\",\n",
    "        },\n",
    "        {\n",
    "            \"step\": 4,\n",
    "            \"thought\": \"Let me store key findings for the final recommendation\",\n",
    "            \"action\": \"memory: store,sector_growth,15%\",\n",
    "            \"observation\": \"Stored: sector_growth = 15%\",\n",
    "        },\n",
    "        {\n",
    "            \"step\": 5,\n",
    "            \"thought\": \"Based on market data and calculations, I can provide a recommendation\",\n",
    "            \"action\": None,\n",
    "            \"observation\": None,\n",
    "            \"final_answer\": \"Based on current market data showing 15% sector growth and strong individual stock performance, renewable energy stocks appear promising. A $10,000 investment could potentially grow to $11,500 based on sector averages. However, consider diversification and your risk tolerance.\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for step_data in steps:\n",
    "        print(f\"\\n🔹 Step {step_data['step']}:\")\n",
    "        print(f\"   💭 Thought: {step_data['thought']}\")\n",
    "\n",
    "        if step_data[\"action\"]:\n",
    "            print(f\"   🔧 Action: {step_data['action']}\")\n",
    "            print(f\"   👀 Observation: {step_data['observation']}\")\n",
    "\n",
    "        if \"final_answer\" in step_data:\n",
    "            print(f\"   ✅ Final Answer: {step_data['final_answer']}\")\n",
    "\n",
    "    return steps\n",
    "\n",
    "\n",
    "financial_demo = financial_analysis_demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d912f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 16: Integration with Other Systems ===\n",
    "print(\"\\n=== 系統整合範例 (System Integration) ===\")\n",
    "\n",
    "\n",
    "class IntegratedReActAgent(AdvancedReActAgent):\n",
    "    \"\"\"ReAct agent with external system integration capabilities\"\"\"\n",
    "\n",
    "    def __init__(self, llm, tools: Dict[str, Any], max_iterations: int = 5):\n",
    "        super().__init__(llm, tools, max_iterations)\n",
    "        self.external_apis = {}\n",
    "        self.data_sources = {}\n",
    "\n",
    "    def register_api(self, name: str, endpoint: str, headers: Dict = None):\n",
    "        \"\"\"Register external API for tool usage\"\"\"\n",
    "        self.external_apis[name] = {\"endpoint\": endpoint, \"headers\": headers or {}}\n",
    "        print(f\"📡 Registered API: {name}\")\n",
    "\n",
    "    def register_data_source(self, name: str, source_type: str, config: Dict):\n",
    "        \"\"\"Register data source (database, file, etc.)\"\"\"\n",
    "        self.data_sources[name] = {\"type\": source_type, \"config\": config}\n",
    "        print(f\"🗄️ Registered data source: {name}\")\n",
    "\n",
    "    def export_reasoning_chain(self, format: str = \"json\") -> str:\n",
    "        \"\"\"Export reasoning chain for external analysis\"\"\"\n",
    "        if format == \"json\":\n",
    "            import json\n",
    "\n",
    "            return json.dumps(self.reasoning_chain, indent=2)\n",
    "        elif format == \"markdown\":\n",
    "            md_content = \"# ReAct Reasoning Chain\\n\\n\"\n",
    "            for i, step in enumerate(self.reasoning_chain, 1):\n",
    "                md_content += f\"## Step {i}\\n\"\n",
    "                if \"response\" in step:\n",
    "                    md_content += f\"**Response:** {step['response']}\\n\\n\"\n",
    "                if \"action\" in step and step[\"action\"]:\n",
    "                    md_content += f\"**Action:** {step['action']}\\n\\n\"\n",
    "                if \"observation\" in step:\n",
    "                    md_content += f\"**Observation:** {step['observation']}\\n\\n\"\n",
    "            return md_content\n",
    "        else:\n",
    "            return str(self.reasoning_chain)\n",
    "\n",
    "\n",
    "# Demo integration capabilities\n",
    "integrated_agent = IntegratedReActAgent(llm, tools_dict)\n",
    "\n",
    "# Register sample integrations\n",
    "integrated_agent.register_api(\"weather_api\", \"https://api.weather.com/v1/current\")\n",
    "integrated_agent.register_data_source(\n",
    "    \"user_db\", \"postgresql\", {\"host\": \"localhost\", \"db\": \"users\"}\n",
    ")\n",
    "\n",
    "print(\"Integration setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2dc8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 17: Performance Monitoring ===\n",
    "import time\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    \"\"\"Monitor ReAct agent performance metrics\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            \"total_queries\": 0,\n",
    "            \"successful_queries\": 0,\n",
    "            \"average_iterations\": 0,\n",
    "            \"average_response_time\": 0,\n",
    "            \"tool_usage\": {},\n",
    "            \"error_count\": 0,\n",
    "        }\n",
    "        self.query_logs = []\n",
    "\n",
    "    def start_query(self, query: str) -> Dict:\n",
    "        \"\"\"Start monitoring a query\"\"\"\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"start_time\": time.time(),\n",
    "            \"iterations\": 0,\n",
    "            \"tools_used\": [],\n",
    "            \"errors\": [],\n",
    "        }\n",
    "\n",
    "    def log_tool_usage(self, log_entry: Dict, tool_name: str):\n",
    "        \"\"\"Log tool usage in current query\"\"\"\n",
    "        log_entry[\"tools_used\"].append(tool_name)\n",
    "        self.metrics[\"tool_usage\"][tool_name] = (\n",
    "            self.metrics[\"tool_usage\"].get(tool_name, 0) + 1\n",
    "        )\n",
    "\n",
    "    def log_error(self, log_entry: Dict, error: str):\n",
    "        \"\"\"Log error in current query\"\"\"\n",
    "        log_entry[\"errors\"].append(error)\n",
    "        self.metrics[\"error_count\"] += 1\n",
    "\n",
    "    def finish_query(self, log_entry: Dict, success: bool):\n",
    "        \"\"\"Finish monitoring a query and update metrics\"\"\"\n",
    "        log_entry[\"end_time\"] = time.time()\n",
    "        log_entry[\"duration\"] = log_entry[\"end_time\"] - log_entry[\"start_time\"]\n",
    "        log_entry[\"success\"] = success\n",
    "\n",
    "        self.query_logs.append(log_entry)\n",
    "        self.metrics[\"total_queries\"] += 1\n",
    "\n",
    "        if success:\n",
    "            self.metrics[\"successful_queries\"] += 1\n",
    "\n",
    "        # Update averages\n",
    "        self._update_averages()\n",
    "\n",
    "    def _update_averages(self):\n",
    "        \"\"\"Update average metrics\"\"\"\n",
    "        if self.query_logs:\n",
    "            total_iterations = sum(log.get(\"iterations\", 0) for log in self.query_logs)\n",
    "            total_time = sum(log.get(\"duration\", 0) for log in self.query_logs)\n",
    "\n",
    "            self.metrics[\"average_iterations\"] = total_iterations / len(self.query_logs)\n",
    "            self.metrics[\"average_response_time\"] = total_time / len(self.query_logs)\n",
    "\n",
    "    def get_report(self) -> str:\n",
    "        \"\"\"Generate performance report\"\"\"\n",
    "        success_rate = (\n",
    "            (self.metrics[\"successful_queries\"] / self.metrics[\"total_queries\"] * 100)\n",
    "            if self.metrics[\"total_queries\"] > 0\n",
    "            else 0\n",
    "        )\n",
    "\n",
    "        report = f\"\"\"\n",
    "📊 ReAct Performance Report\n",
    "==========================\n",
    "Total Queries: {self.metrics['total_queries']}\n",
    "Successful: {self.metrics['successful_queries']} ({success_rate:.1f}%)\n",
    "Average Iterations: {self.metrics['average_iterations']:.1f}\n",
    "Average Response Time: {self.metrics['average_response_time']:.2f}s\n",
    "Errors: {self.metrics['error_count']}\n",
    "\n",
    "Tool Usage:\n",
    "{chr(10).join(f'  {tool}: {count}' for tool, count in self.metrics['tool_usage'].items())}\n",
    "\"\"\"\n",
    "        return report\n",
    "\n",
    "\n",
    "# Demo performance monitoring\n",
    "monitor = PerformanceMonitor()\n",
    "\n",
    "# Simulate some queries\n",
    "for i in range(3):\n",
    "    log = monitor.start_query(f\"Sample query {i+1}\")\n",
    "    log[\"iterations\"] = i + 2\n",
    "    monitor.log_tool_usage(log, \"search\")\n",
    "    monitor.log_tool_usage(log, \"calculator\")\n",
    "    if i == 2:  # Simulate error in last query\n",
    "        monitor.log_error(log, \"Tool timeout\")\n",
    "    monitor.finish_query(log, success=(i != 2))\n",
    "    time.sleep(0.1)  # Small delay for realistic timing\n",
    "\n",
    "print(monitor.get_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ab29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 18: Best Practices Summary ===\n",
    "print(\"=== 最佳實踐總結 (Best Practices Summary) ===\")\n",
    "\n",
    "best_practices = {\n",
    "    \"設計原則 (Design Principles)\": [\n",
    "        \"保持工具功能單一且明確\",\n",
    "        \"實作健全的錯誤處理機制\",\n",
    "        \"使用結構化的提示格式\",\n",
    "        \"限制最大迭代次數防止無限循環\",\n",
    "        \"提供清晰的工具使用說明\",\n",
    "    ],\n",
    "    \"性能優化 (Performance Optimization)\": [\n",
    "        \"快取常用查詢結果\",\n",
    "        \"並行執行獨立工具調用\",\n",
    "        \"使用輕量級模型進行簡單任務\",\n",
    "        \"實作智能提前終止機制\",\n",
    "        \"監控和分析工具使用模式\",\n",
    "    ],\n",
    "    \"可靠性 (Reliability)\": [\n",
    "        \"實作重試機制處理暫時性錯誤\",\n",
    "        \"提供降級策略當主要工具失效\",\n",
    "        \"驗證工具輸出格式和內容\",\n",
    "        \"記錄詳細的執行日誌\",\n",
    "        \"定期測試所有工具功能\",\n",
    "    ],\n",
    "    \"可維護性 (Maintainability)\": [\n",
    "        \"模組化工具設計便於擴展\",\n",
    "        \"使用配置文件管理工具參數\",\n",
    "        \"提供完整的文檔和範例\",\n",
    "        \"實作自動化測試套件\",\n",
    "        \"版本控制工具和提示模板\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "for category, practices in best_practices.items():\n",
    "    print(f\"\\n🎯 {category}:\")\n",
    "    for practice in practices:\n",
    "        print(f\"   • {practice}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d2c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 19: Final Smoke Test ===\n",
    "def comprehensive_smoke_test():\n",
    "    \"\"\"Comprehensive smoke test for all ReAct components\"\"\"\n",
    "    print(\"🧪 綜合測試 (Comprehensive Smoke Test)\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    test_results = {}\n",
    "\n",
    "    # Test 1: Basic ReAct functionality\n",
    "    try:\n",
    "        basic_agent = ReActAgent(llm, tools_dict, max_iterations=2)\n",
    "        test_results[\"basic_agent\"] = \"✅ PASS\"\n",
    "    except Exception as e:\n",
    "        test_results[\"basic_agent\"] = f\"❌ FAIL: {e}\"\n",
    "\n",
    "    # Test 2: Advanced agent features\n",
    "    try:\n",
    "        adv_agent = AdvancedReActAgent(llm, tools_dict)\n",
    "        adv_agent.add_context(\"test context\")\n",
    "        decomp = adv_agent.plan_decomposition(\"test question\")\n",
    "        test_results[\"advanced_features\"] = \"✅ PASS\"\n",
    "    except Exception as e:\n",
    "        test_results[\"advanced_features\"] = f\"❌ FAIL: {e}\"\n",
    "\n",
    "    # Test 3: Performance monitoring\n",
    "    try:\n",
    "        perf_monitor = PerformanceMonitor()\n",
    "        log = perf_monitor.start_query(\"test\")\n",
    "        perf_monitor.finish_query(log, True)\n",
    "        report = perf_monitor.get_report()\n",
    "        test_results[\"performance_monitoring\"] = \"✅ PASS\"\n",
    "    except Exception as e:\n",
    "        test_results[\"performance_monitoring\"] = f\"❌ FAIL: {e}\"\n",
    "\n",
    "    # Test 4: Integration capabilities\n",
    "    try:\n",
    "        int_agent = IntegratedReActAgent(llm, tools_dict)\n",
    "        int_agent.register_api(\"test_api\", \"http://test.com\")\n",
    "        export = int_agent.export_reasoning_chain(\"json\")\n",
    "        test_results[\"integration\"] = \"✅ PASS\"\n",
    "    except Exception as e:\n",
    "        test_results[\"integration\"] = f\"❌ FAIL: {e}\"\n",
    "\n",
    "    # Test 5: All tools functional\n",
    "    tool_tests = {}\n",
    "    for tool_name, tool in tools_dict.items():\n",
    "        try:\n",
    "            if tool_name == \"calculator\":\n",
    "                result = tool.execute(\"1 + 1\")\n",
    "                tool_tests[tool_name] = \"✅ PASS\" if \"2\" in result else \"❌ FAIL\"\n",
    "            elif tool_name == \"memory\":\n",
    "                tool.execute(\"store\", \"test\", \"value\")\n",
    "                result = tool.execute(\"retrieve\", \"test\")\n",
    "                tool_tests[tool_name] = \"✅ PASS\" if \"value\" in result else \"❌ FAIL\"\n",
    "            else:\n",
    "                # For search tool, just check it doesn't crash\n",
    "                result = tool.execute(\"test\")\n",
    "                tool_tests[tool_name] = \"✅ PASS\"\n",
    "        except Exception as e:\n",
    "            tool_tests[tool_name] = f\"❌ FAIL: {e}\"\n",
    "\n",
    "    # Print results\n",
    "    print(\"Core Components:\")\n",
    "    for test_name, result in test_results.items():\n",
    "        print(f\"  {result} {test_name}\")\n",
    "\n",
    "    print(\"\\nTool Tests:\")\n",
    "    for tool_name, result in tool_tests.items():\n",
    "        print(f\"  {result} {tool_name}\")\n",
    "\n",
    "    # Overall status\n",
    "    all_passed = all(\n",
    "        \"✅\" in result for result in {**test_results, **tool_tests}.values()\n",
    "    )\n",
    "    overall_status = \"✅ ALL TESTS PASSED\" if all_passed else \"⚠️ SOME TESTS FAILED\"\n",
    "    print(f\"\\n{overall_status}\")\n",
    "\n",
    "    return {\"core\": test_results, \"tools\": tool_tests, \"overall\": all_passed}\n",
    "\n",
    "\n",
    "final_test_results = comprehensive_smoke_test()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📝 Notebook nb14_react_multistep_reasoning.ipynb completed!\")\n",
    "print(\"✅ Ready for Git commit and next stage planning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ccbc4b",
   "metadata": {},
   "source": [
    "\n",
    "## 6. 本章小結\n",
    "\n",
    "### 🎯 完成項目 (Completed Items)\n",
    "- **ReAct 核心引擎**：實作完整的 Reasoning-Acting 循環機制\n",
    "- **工具生態系統**：搜尋、計算、記憶三大基礎工具\n",
    "- **多步推理能力**：複雜問題分解與逐步解決\n",
    "- **錯誤恢復機制**：處理工具失效與推理中斷\n",
    "- **性能監控**：追蹤執行效率與工具使用統計\n",
    "- **可視化界面**：推理鏈展示與決策過程透明化\n",
    "\n",
    "### 🧠 核心概念要點 (Key Concepts)\n",
    "- **Thought-Action-Observation 循環**：ReAct 的核心運作模式\n",
    "- **工具抽象化**：統一的工具接口設計原則\n",
    "- **推理策略比較**：ReAct vs CoT vs Direct 的適用場景\n",
    "- **錯誤處理策略**：重試、降級、提前終止機制\n",
    "- **性能優化技巧**：快取、並行、智能終止\n",
    "\n",
    "### ⚠️ 常見陷阱 (Common Pitfalls)\n",
    "- **無限循環風險**：必須設置最大迭代次數限制\n",
    "- **工具調用格式**：需要嚴格的解析規則避免格式錯誤\n",
    "- **上下文長度**：推理鏈過長可能超出模型限制\n",
    "- **工具可靠性**：外部API可能失效需要降級策略\n",
    "- **成本控制**：多步推理會增加 token 消耗\n",
    "\n",
    "### 🚀 下一步建議 (Next Steps)\n",
    "\n",
    "**立即可行的擴展**：\n",
    "1. **更多工具類型**：檔案操作、資料庫查詢、API 調用\n",
    "2. **智能工具選擇**：根據問題類型自動選擇最佳工具組合\n",
    "3. **並行推理**：獨立子任務的並行執行\n",
    "\n",
    "**整合其他 Notebook**：\n",
    "- **nb13 (Function Calling)**：整合更豐富的工具庫\n",
    "- **nb26 (RAG Basic)**：結合檢索增強生成\n",
    "- **nb29 (Multi-Agent)**：多代理協作推理\n",
    "\n",
    "**建議下一個重點**：\n",
    "建議先完成 **nb29 Multi-Agent Collaboration**，因為：\n",
    "- ReAct 為單一代理推理，多代理是自然延伸\n",
    "- 可重用本章的工具和推理框架\n",
    "- 為後續的自動化流程 (nb30) 打下基礎\n",
    "\n",
    "準備好繼續下一個 Notebook 的開發！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
