{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a07e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 1: Shared Cache Bootstrap ===\n",
    "import os, pathlib, torch\n",
    "\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"/mnt/ai/cache\")\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"[Cache] Root: {AI_CACHE_ROOT}\")\n",
    "print(f\"[GPU] Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"[GPU] Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(\n",
    "        f\"[GPU] Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac69bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 2: Import Dependencies ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Set device with memory-efficient defaults\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af26b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: CIFAR-10 Dataset Loading & Preprocessing ===\n",
    "# CIFAR-10 classes\n",
    "classes = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")\n",
    "\n",
    "# Data transforms with augmentation for training\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Download and load datasets (cached in AI_CACHE_ROOT)\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=f\"{AI_CACHE_ROOT}/data\", train=True, download=True, transform=transform_train\n",
    ")\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=f\"{AI_CACHE_ROOT}/data\", train=False, download=True, transform=transform_test\n",
    ")\n",
    "\n",
    "# Low-VRAM friendly batch sizes\n",
    "batch_size = 64 if torch.cuda.is_available() else 32\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Training samples: {len(trainset)}\")\n",
    "print(f\"Test samples: {len(testset)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "\n",
    "# Visualize sample images\n",
    "def show_sample_images(dataloader, num_images=8):\n",
    "    dataiter = iter(dataloader)\n",
    "    images, labels = next(dataiter)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    for i in range(num_images):\n",
    "        ax = axes[i // 4, i % 4]\n",
    "        # Denormalize for display\n",
    "        img = images[i] * torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)\n",
    "        img += torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "\n",
    "        ax.imshow(img.permute(1, 2, 0))\n",
    "        ax.set_title(f\"{classes[labels[i]]}\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_sample_images(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c341891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 4: CNN Model Architecture ===\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple CNN for CIFAR-10 classification\n",
    "    Features: Conv layers, BatchNorm, Dropout, Global Average Pooling\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=10, dropout_rate=0.3):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        # Feature extraction layers\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1: 32x32 -> 16x16\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(dropout_rate),\n",
    "            # Block 2: 16x16 -> 8x8\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(dropout_rate),\n",
    "            # Block 3: 8x8 -> 4x4\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(dropout_rate),\n",
    "        )\n",
    "\n",
    "        # Classifier with Global Average Pooling\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = SimpleCNN(num_classes=10).to(device)\n",
    "\n",
    "\n",
    "# Model summary\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"Model parameters: {count_parameters(model):,}\")\n",
    "print(f\"Model size: {count_parameters(model) * 4 / 1e6:.2f} MB (fp32)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05fb18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 5: Training Configuration ===\n",
    "# Training hyperparameters (low-VRAM friendly)\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training tracking\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    \"\"\"Evaluate model on given dataloader\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in dataloader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec11d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 6: Training Loop ===\n",
    "print(\"Starting training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Training loop with progress bar\n",
    "    pbar = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for i, (inputs, labels) in enumerate(pbar):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        if i % 100 == 99:\n",
    "            avg_loss = running_loss / 100\n",
    "            accuracy = 100 * correct / total\n",
    "            pbar.set_postfix({\"Loss\": f\"{avg_loss:.3f}\", \"Acc\": f\"{accuracy:.1f}%\"})\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Epoch statistics\n",
    "    train_acc = 100 * correct / total\n",
    "    val_acc, val_loss = evaluate_model(model, testloader, device)\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "        f\"Train Acc: {train_acc:.2f}% - \"\n",
    "        f\"Val Acc: {val_acc:.2f}% - \"\n",
    "        f\"Val Loss: {val_loss:.3f}\"\n",
    "    )\n",
    "\n",
    "    # Step scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in {training_time:.1f} seconds\")\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies, \"b-\", label=\"Training\")\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies, \"r-\", label=\"Validation\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Training & Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(\n",
    "    range(1, num_epochs + 1),\n",
    "    [scheduler.get_last_lr()[0] * (0.5 ** (i // 5)) for i in range(num_epochs)],\n",
    ")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Learning Rate Schedule\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6308ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 7: Model Evaluation & Visualization ===\n",
    "# Final evaluation on test set\n",
    "model.eval()\n",
    "all_predicted = []\n",
    "all_labels = []\n",
    "all_outputs = []\n",
    "\n",
    "print(\"Evaluating on test set...\")\n",
    "with torch.no_grad():\n",
    "    for data, targets in tqdm(testloader):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_predicted.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(targets.cpu().numpy())\n",
    "        all_outputs.extend(F.softmax(outputs, dim=1).cpu().numpy())\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(all_labels, all_predicted, target_names=classes))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_predicted)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes\n",
    ")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Per-class accuracy\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "for i, acc in enumerate(class_accuracy):\n",
    "    print(f\"{classes[i]}: {acc:.3f}\")\n",
    "\n",
    "\n",
    "# Visualize predictions\n",
    "def show_predictions(model, testloader, device, num_images=8):\n",
    "    model.eval()\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = next(dataiter)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "    for i in range(num_images):\n",
    "        ax = axes[i // 4, i % 4]\n",
    "\n",
    "        # Denormalize image for display\n",
    "        img = images[i].cpu()\n",
    "        img = img * torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)\n",
    "        img += torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "\n",
    "        ax.imshow(img.permute(1, 2, 0))\n",
    "\n",
    "        true_label = classes[labels[i]]\n",
    "        pred_label = classes[predicted[i]]\n",
    "        confidence = probabilities[i][predicted[i]].item()\n",
    "\n",
    "        color = \"green\" if labels[i] == predicted[i] else \"red\"\n",
    "        ax.set_title(\n",
    "            f\"True: {true_label}\\nPred: {pred_label} ({confidence:.2f})\",\n",
    "            color=color,\n",
    "            fontsize=10,\n",
    "        )\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_predictions(model, testloader, device)\n",
    "\n",
    "# Save model checkpoint\n",
    "model_path = f\"{AI_CACHE_ROOT}/models\"\n",
    "pathlib.Path(model_path).mkdir(parents=True, exist_ok=True)\n",
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"epoch\": num_epochs,\n",
    "        \"val_accuracy\": val_accuracies[-1],\n",
    "        \"model_config\": {\"num_classes\": 10, \"dropout_rate\": 0.3},\n",
    "    },\n",
    "    f\"{model_path}/cifar10_cnn_checkpoint.pth\",\n",
    ")\n",
    "\n",
    "print(f\"Model saved to {model_path}/cifar10_cnn_checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6aa59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 8: Smoke Test ===\n",
    "print(\"=== Smoke Test: Model Loading & Inference ===\")\n",
    "\n",
    "# Test model loading\n",
    "checkpoint = torch.load(f\"{model_path}/cifar10_cnn_checkpoint.pth\", map_location=device)\n",
    "test_model = SimpleCNN(**checkpoint[\"model_config\"]).to(device)\n",
    "test_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "# Test inference on a single batch\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "    test_output = test_model(test_input)\n",
    "    test_prediction = torch.argmax(test_output, dim=1)\n",
    "\n",
    "print(f\"✅ Model loading: SUCCESS\")\n",
    "print(f\"✅ Inference shape: {test_output.shape}\")\n",
    "print(f\"✅ Prediction class: {classes[test_prediction.item()]}\")\n",
    "\n",
    "# Memory usage summary\n",
    "if torch.cuda.is_available():\n",
    "    memory_used = torch.cuda.max_memory_allocated() / 1e9\n",
    "    print(f\"✅ Peak GPU memory: {memory_used:.2f} GB\")\n",
    "\n",
    "print(f\"✅ Final validation accuracy: {val_accuracies[-1]:.2f}%\")\n",
    "print(\"✅ All tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2417071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 9: Usage Notes & Extensions ===\n",
    "print(\n",
    "    \"\"\"\n",
    "=== 何時使用 CNN (When to use CNN) ===\n",
    "\n",
    "🎯 適用場景 (Use Cases):\n",
    "• 影像分類、物件偵測、影像分割\n",
    "• 任何具有空間結構的資料 (圖片、醫學影像、衛星圖)\n",
    "• 需要平移不變性 (translation invariance) 的任務\n",
    "\n",
    "⚙️ 關鍵參數調整 (Key Parameters):\n",
    "• batch_size: 根據 GPU 記憶體調整 (4GB: 32, 8GB: 64, 16GB+: 128)\n",
    "• learning_rate: 0.001 (Adam) 或 0.01 (SGD)\n",
    "• dropout_rate: 0.2-0.5 防止過擬合\n",
    "• data_augmentation: 小資料集必用\n",
    "\n",
    "🚀 效能優化 (Performance Tips):\n",
    "• 使用 BatchNorm 加速收斂\n",
    "• Global Average Pooling 減少參數\n",
    "• Mixed precision training (torch.cuda.amp)\n",
    "• 梯度累積處理大 batch size\n",
    "\n",
    "🔧 常見問題 (Common Issues):\n",
    "• 過擬合: 增加 Dropout、Data Augmentation\n",
    "• 收斂慢: 檢查學習率、使用預訓練模型\n",
    "• 記憶體不足: 減少 batch_size、使用 gradient checkpointing\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e956cf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Smoke Test Cell (5 lines) ===\n",
    "assert torch.cuda.is_available() or True  # Works on CPU too\n",
    "assert model.training == False  # Model in eval mode\n",
    "assert val_accuracies[-1] > 50.0  # Reasonable accuracy threshold\n",
    "assert os.path.exists(f\"{AI_CACHE_ROOT}/models/cifar10_cnn_checkpoint.pth\")\n",
    "print(\"✅ All smoke tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5396ea47",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 6. 本章小結\n",
    "\n",
    "### ✅ 完成項目 (Completed Items)\n",
    "- **CNN 架構實作**：包含卷積、批次正規化、池化、Dropout 的完整模型\n",
    "- **CIFAR-10 訓練流程**：資料載入、增強、訓練、評估的端對端流程\n",
    "- **低 VRAM 優化**：支援 4GB+ GPU，包含 CPU 後備方案\n",
    "- **模型評估**：準確率、混淆矩陣、分類報告、預測視覺化\n",
    "- **模型持久化**：檢查點儲存與載入機制\n",
    "\n",
    "### 🧠 核心原理 (Core Concepts)\n",
    "- **空間不變性 (Spatial Invariance)**：CNN 透過權重共享學習局部特徵\n",
    "- **階層式特徵學習**：淺層學習邊緣，深層學習複雜模式\n",
    "- **正規化技術**：BatchNorm 加速訓練，Dropout 防止過擬合\n",
    "- **資料增強**：RandomFlip、Rotation 提升模型泛化能力\n",
    "\n",
    "### ⚠️ 常見陷阱 (Common Pitfalls)\n",
    "- **記憶體爆炸**：batch_size 過大導致 CUDA OOM\n",
    "- **梯度消失**：網路過深時使用 ResNet 或 BatchNorm\n",
    "- **過擬合**：小資料集時必須使用 Dropout 和 Data Augmentation\n",
    "- **學習率設定**：過大導致震盪，過小導致收斂慢\n",
    "\n",
    "### 🚀 下一步建議 (Next Steps)\n",
    "1. **轉移學習**：使用預訓練 ResNet/EfficientNet 提升效果\n",
    "2. **進階增強**：CutMix、MixUp、AutoAugment 技術\n",
    "3. **架構搜索**：嘗試 MobileNet、ShuffleNet 等輕量化模型\n",
    "4. **多 GPU 訓練**：DataParallel 或 DistributedDataParallel\n",
    "\n",
    "**準備進入 nb05_lstm_text_generation.ipynb (LSTM 文字生成)，或您想優先學習其他主題？**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
